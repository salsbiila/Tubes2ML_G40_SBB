{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "479b34dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a859a63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-29 09:40:36.498848: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-29 09:40:36.755535: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1748486436.847350  323749 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1748486436.874530  323749 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1748486437.096593  323749 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748486437.096662  323749 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748486437.096663  323749 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748486437.096664  323749 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-29 09:40:37.118987: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, Flatten, Dense, ReLU as KerasReLU, BatchNormalization, Dropout, InputLayer, GlobalAveragePooling2D, Lambda, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy as KerasSCCE # Use alias\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a342a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "from src.cnn.cnn import CNN\n",
    "from src.cnn.layers import Conv2DLayer, ReLULayer, PoolingLayer, FlattenLayer, DenseLayer, SoftmaxLayer, BatchNormalizationLayer, DropoutLayer\n",
    "from src.cnn.losses import SparseCategoricalCrossentropy as ScratchSCCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9327b1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs detected and configured.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1748486439.430381  323749 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9706 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(f\"{len(gpus)} Physical GPUs, {len(logical_gpus)} Logical GPUs detected and configured.\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"No GPU detected. TensorFlow will use CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3d348e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train_full, y_train_full), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "807858db",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_full = x_train_full.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3fdb7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    x_train_full, y_train_full, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18e2b891",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "input_shape = x_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f33c0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_sparse = y_train.flatten()\n",
    "y_val_sparse = y_val.flatten()\n",
    "y_test_sparse = y_test.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb3d105b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: (40000, 32, 32, 3), y_train_sparse: (40000,)\n",
      "x_val: (10000, 32, 32, 3), y_val_sparse: (10000,)\n",
      "x_test: (10000, 32, 32, 3), y_test_sparse: (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"x_train: {x_train.shape}, y_train_sparse: {y_train_sparse.shape}\")\n",
    "print(f\"x_val: {x_val.shape}, y_val_sparse: {y_val_sparse.shape}\")\n",
    "print(f\"x_test: {x_test.shape}, y_test_sparse: {y_test_sparse.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c91e5907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_cnn(\n",
    "    input_shape, num_classes,\n",
    "    conv_blocks=[\n",
    "        {'filters': 32, 'kernel_size': (3,3), 'pool': 'max', 'batch_norm': True, 'dropout': 0.25},\n",
    "        {'filters': 64, 'kernel_size': (3,3), 'pool': 'max', 'batch_norm': True, 'dropout': 0.25}\n",
    "    ],\n",
    "    dense_layers_units=[512],\n",
    "    dense_dropout=0.5,\n",
    "    global_pooling=None\n",
    "    ):\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=input_shape))\n",
    "\n",
    "    for block_params in conv_blocks:\n",
    "        model.add(Conv2D(filters=block_params['filters'], kernel_size=block_params['kernel_size'], padding='same'))\n",
    "        if block_params.get('batch_norm'):\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(KerasReLU())\n",
    "        \n",
    "        pool = block_params.get('pool')\n",
    "        if pool == 'max':\n",
    "            model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        elif pool == 'average':\n",
    "            model.add(AveragePooling2D(pool_size=(2, 2)))\n",
    "        \n",
    "        if block_params.get('dropout') and block_params['dropout'] > 0:\n",
    "            model.add(Dropout(block_params['dropout']))\n",
    "            \n",
    "    if global_pooling == 'avg':\n",
    "        model.add(GlobalAveragePooling2D())\n",
    "    elif global_pooling == 'max':\n",
    "        model.add(Lambda(lambda x: tf.reduce_max(x, axis=[1,2])))\n",
    "    else:\n",
    "        if not isinstance(model.layers[-1], (GlobalAveragePooling2D, Lambda, Flatten)):\n",
    "             model.add(Flatten())\n",
    "    \n",
    "    for units in dense_layers_units:\n",
    "        model.add(Dense(units=units))\n",
    "        model.add(KerasReLU())\n",
    "        if dense_dropout > 0:\n",
    "            model.add(Dropout(dense_dropout))\n",
    "    \n",
    "    model.add(Dense(units=num_classes))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b51f5edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_conv_params = [\n",
    "    {'filters': 32, 'kernel_size': (3,3), 'batch_norm': True, 'dropout': 0.0},\n",
    "    {'filters': 32, 'kernel_size': (3,3), 'pool': 'max', 'batch_norm': True, 'dropout': 0.2},\n",
    "    {'filters': 64, 'kernel_size': (3,3), 'batch_norm': True, 'dropout': 0.0},\n",
    "    {'filters': 64, 'kernel_size': (3,3), 'pool': 'max', 'batch_norm': True, 'dropout': 0.3},\n",
    "    {'filters': 128, 'kernel_size': (3,3), 'batch_norm': True, 'dropout': 0.0},\n",
    "    {'filters': 128, 'kernel_size': (3,3), 'pool': 'max', 'batch_norm': True, 'dropout': 0.4},\n",
    "]\n",
    "\n",
    "base_dense_units = [521]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2de7db2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/salsabiila/miniconda3/envs/ml_venv/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">521</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,067,529</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">521</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">521</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,220</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu (\u001b[38;5;33mReLU\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m9,248\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_1 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_2 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_3 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_4 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │       \u001b[38;5;34m147,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_5 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m521\u001b[0m)            │     \u001b[38;5;34m1,067,529\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_6 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m521\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m521\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m5,220\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,361,549</span> (5.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,361,549\u001b[0m (5.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,360,653</span> (5.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,360,653\u001b[0m (5.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> (3.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m896\u001b[0m (3.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "keras_cnn_model = keras_cnn(\n",
    "    input_shape, num_classes,\n",
    "    conv_blocks=base_conv_params,\n",
    "    dense_layers_units=base_dense_units,\n",
    "    dense_dropout=0.5\n",
    ")\n",
    "keras_cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9b09e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fdf5c5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.1\n",
    ")\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87cf8f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/salsabiila/miniconda3/envs/ml_venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1748486444.912430  324807 service.cc:152] XLA service 0x7f46580140d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1748486444.912592  324807 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3060, Compute Capability 8.6\n",
      "2025-05-29 09:40:44.998371: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1748486445.492203  324807 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  2/625\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m31s\u001b[0m 50ms/step - accuracy: 0.1055 - loss: 5.1798   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1748486452.297431  324807 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m624/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.2659 - loss: 2.1481"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-29 09:41:04.472074: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_207', 52 bytes spill stores, 52 bytes spill loads\n",
      "\n",
      "2025-05-29 09:41:04.526009: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_207', 52 bytes spill stores, 52 bytes spill loads\n",
      "\n",
      "2025-05-29 09:41:04.570264: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_207', 164 bytes spill stores, 164 bytes spill loads\n",
      "\n",
      "2025-05-29 09:41:04.860239: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_207', 1228 bytes spill stores, 1228 bytes spill loads\n",
      "\n",
      "2025-05-29 09:41:04.948337: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_207', 1092 bytes spill stores, 1092 bytes spill loads\n",
      "\n",
      "2025-05-29 09:41:06.923665: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_207', 52 bytes spill stores, 52 bytes spill loads\n",
      "\n",
      "2025-05-29 09:41:06.969567: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_207', 52 bytes spill stores, 52 bytes spill loads\n",
      "\n",
      "2025-05-29 09:41:07.221319: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_207', 1228 bytes spill stores, 1228 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.2661 - loss: 2.1471 - val_accuracy: 0.3960 - val_loss: 1.6640 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - accuracy: 0.4372 - loss: 1.5408 - val_accuracy: 0.4771 - val_loss: 1.4768 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - accuracy: 0.5106 - loss: 1.3519 - val_accuracy: 0.5489 - val_loss: 1.2754 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - accuracy: 0.5609 - loss: 1.2319 - val_accuracy: 0.5636 - val_loss: 1.2878 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - accuracy: 0.5968 - loss: 1.1444 - val_accuracy: 0.6243 - val_loss: 1.0457 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - accuracy: 0.6309 - loss: 1.0540 - val_accuracy: 0.6674 - val_loss: 0.9440 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - accuracy: 0.6611 - loss: 0.9872 - val_accuracy: 0.6525 - val_loss: 0.9776 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - accuracy: 0.6705 - loss: 0.9548 - val_accuracy: 0.6421 - val_loss: 1.0878 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 18ms/step - accuracy: 0.6868 - loss: 0.9001 - val_accuracy: 0.7299 - val_loss: 0.7632 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.7026 - loss: 0.8806 - val_accuracy: 0.7214 - val_loss: 0.7985 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.7152 - loss: 0.8488 - val_accuracy: 0.7396 - val_loss: 0.7853 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.7212 - loss: 0.8118 - val_accuracy: 0.7782 - val_loss: 0.6306 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - accuracy: 0.7333 - loss: 0.7860 - val_accuracy: 0.7649 - val_loss: 0.6982 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.7456 - loss: 0.7501 - val_accuracy: 0.7471 - val_loss: 0.7550 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.7533 - loss: 0.7338 - val_accuracy: 0.7235 - val_loss: 0.8657 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.7584 - loss: 0.7064 - val_accuracy: 0.7769 - val_loss: 0.6383 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.7671 - loss: 0.6881 - val_accuracy: 0.7906 - val_loss: 0.6122 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.7697 - loss: 0.6772 - val_accuracy: 0.8054 - val_loss: 0.5657 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.7709 - loss: 0.6753 - val_accuracy: 0.7529 - val_loss: 0.7437 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 18ms/step - accuracy: 0.7817 - loss: 0.6421 - val_accuracy: 0.7715 - val_loss: 0.6958 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.7840 - loss: 0.6316 - val_accuracy: 0.7969 - val_loss: 0.6090 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - accuracy: 0.7885 - loss: 0.6157 - val_accuracy: 0.7989 - val_loss: 0.6087 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m623/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7914 - loss: 0.6080\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - accuracy: 0.7914 - loss: 0.6080 - val_accuracy: 0.7877 - val_loss: 0.6284 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 18ms/step - accuracy: 0.8046 - loss: 0.5779 - val_accuracy: 0.8316 - val_loss: 0.5045 - learning_rate: 2.0000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.8160 - loss: 0.5402 - val_accuracy: 0.8315 - val_loss: 0.5204 - learning_rate: 2.0000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 18ms/step - accuracy: 0.8197 - loss: 0.5228 - val_accuracy: 0.8456 - val_loss: 0.4631 - learning_rate: 2.0000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.8206 - loss: 0.5217 - val_accuracy: 0.8399 - val_loss: 0.4906 - learning_rate: 2.0000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.8237 - loss: 0.5223 - val_accuracy: 0.8439 - val_loss: 0.4610 - learning_rate: 2.0000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.8259 - loss: 0.5132 - val_accuracy: 0.8522 - val_loss: 0.4446 - learning_rate: 2.0000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.8296 - loss: 0.5021 - val_accuracy: 0.8497 - val_loss: 0.4526 - learning_rate: 2.0000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.8320 - loss: 0.4939 - val_accuracy: 0.8338 - val_loss: 0.5027 - learning_rate: 2.0000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - accuracy: 0.8283 - loss: 0.4972 - val_accuracy: 0.8252 - val_loss: 0.5342 - learning_rate: 2.0000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 18ms/step - accuracy: 0.8323 - loss: 0.4893 - val_accuracy: 0.8393 - val_loss: 0.4848 - learning_rate: 2.0000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m624/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8324 - loss: 0.4893\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - accuracy: 0.8324 - loss: 0.4893 - val_accuracy: 0.8461 - val_loss: 0.4601 - learning_rate: 2.0000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - accuracy: 0.8371 - loss: 0.4781 - val_accuracy: 0.8498 - val_loss: 0.4519 - learning_rate: 4.0000e-05\n",
      "Epoch 36/100\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 18ms/step - accuracy: 0.8374 - loss: 0.4795 - val_accuracy: 0.8476 - val_loss: 0.4589 - learning_rate: 4.0000e-05\n",
      "Epoch 37/100\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - accuracy: 0.8364 - loss: 0.4789 - val_accuracy: 0.8449 - val_loss: 0.4749 - learning_rate: 4.0000e-05\n",
      "Epoch 38/100\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.8385 - loss: 0.4740 - val_accuracy: 0.8547 - val_loss: 0.4469 - learning_rate: 4.0000e-05\n",
      "Epoch 39/100\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.8384 - loss: 0.4650 - val_accuracy: 0.8561 - val_loss: 0.4350 - learning_rate: 4.0000e-05\n",
      "Epoch 40/100\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.8347 - loss: 0.4769 - val_accuracy: 0.8510 - val_loss: 0.4534 - learning_rate: 4.0000e-05\n",
      "Epoch 41/100\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.8387 - loss: 0.4658 - val_accuracy: 0.8514 - val_loss: 0.4513 - learning_rate: 4.0000e-05\n",
      "Epoch 42/100\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.8445 - loss: 0.4560 - val_accuracy: 0.8506 - val_loss: 0.4507 - learning_rate: 4.0000e-05\n",
      "Epoch 43/100\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - accuracy: 0.8341 - loss: 0.4733 - val_accuracy: 0.8479 - val_loss: 0.4614 - learning_rate: 4.0000e-05\n",
      "Epoch 44/100\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8379 - loss: 0.4653\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.8379 - loss: 0.4654 - val_accuracy: 0.8517 - val_loss: 0.4491 - learning_rate: 4.0000e-05\n",
      "Epoch 45/100\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - accuracy: 0.8396 - loss: 0.4628 - val_accuracy: 0.8527 - val_loss: 0.4448 - learning_rate: 1.0000e-05\n",
      "Epoch 46/100\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - accuracy: 0.8435 - loss: 0.4561 - val_accuracy: 0.8506 - val_loss: 0.4502 - learning_rate: 1.0000e-05\n",
      "Epoch 47/100\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.8434 - loss: 0.4556 - val_accuracy: 0.8516 - val_loss: 0.4476 - learning_rate: 1.0000e-05\n",
      "Epoch 48/100\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.8418 - loss: 0.4596 - val_accuracy: 0.8498 - val_loss: 0.4525 - learning_rate: 1.0000e-05\n",
      "Epoch 49/100\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - accuracy: 0.8439 - loss: 0.4556 - val_accuracy: 0.8511 - val_loss: 0.4496 - learning_rate: 1.0000e-05\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n"
     ]
    }
   ],
   "source": [
    "keras_cnn_model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss=KerasSCCE(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "epochs_keras = 100\n",
    "batch_size_keras = 64\n",
    "history_keras = keras_cnn_model.fit(\n",
    "    datagen.flow(x_train, y_train, batch_size=batch_size_keras),\n",
    "    epochs=epochs_keras,\n",
    "    validation_data=(x_val, y_val),\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b90c73e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\n",
      "Enhanced Keras Model - Test Accuracy: 0.8503, Macro F1-Score: 0.8485\n"
     ]
    }
   ],
   "source": [
    "loss_keras, accuracy_keras = keras_cnn_model.evaluate(x_test, y_test, verbose=0)\n",
    "y_pred_keras_proba = tf.nn.softmax(keras_cnn_model.predict(x_test)).numpy()\n",
    "y_pred_keras = np.argmax(y_pred_keras_proba, axis=1)\n",
    "f1_keras = f1_score(y_test_sparse, y_pred_keras, average='macro')\n",
    "\n",
    "print(f\"\\nEnhanced Keras Model - Test Accuracy: {accuracy_keras:.4f}, Macro F1-Score: {f1_keras:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57d62f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0: conv2d\n",
      "  Param 0 wieight: [[[[-8.87642056e-02  1.15612082e-01 -1.60254180e-01  9.44101661e-02\n",
      "     4.90332842e-02 -1.08593315e-01  2.18233503e-02  1.03773102e-01\n",
      "     2.35715434e-01 -2.21581832e-01 -7.61660188e-02  2.31210932e-01\n",
      "    -3.13957594e-02  6.24771714e-02 -2.03501973e-02 -6.41558170e-02\n",
      "    -1.52371628e-02  1.21673904e-01  1.49819195e-01  1.27031907e-01\n",
      "    -1.79299116e-01 -1.45356460e-02  1.96847077e-02  6.96292222e-02\n",
      "     1.77288249e-01  3.02250236e-01 -8.34366586e-03 -3.32460031e-02\n",
      "    -5.18235192e-02  8.06169733e-02 -1.87521189e-01 -1.64868996e-01]\n",
      "   [ 4.92994040e-02 -1.68149322e-01  1.61553491e-02 -1.84713937e-02\n",
      "    -1.57137774e-02 -6.81192651e-02  1.06796451e-01 -5.22906408e-02\n",
      "    -1.95008010e-01  2.48125158e-02  2.15829849e-01  2.67441213e-01\n",
      "    -9.81164724e-02  1.09132737e-01  2.07137913e-01  1.18858188e-01\n",
      "    -8.24823827e-02 -1.15428334e-02  6.50931969e-02 -1.39431760e-01\n",
      "     1.74378514e-01  1.44804046e-01 -1.62510306e-03  1.90612614e-01\n",
      "    -2.00699061e-01  2.59997517e-01 -1.86742440e-01  2.34244615e-01\n",
      "     1.85544658e-02 -1.31937072e-01 -1.72686592e-01  4.23718477e-03]\n",
      "   [ 1.20457664e-01  1.31968647e-01  2.02564280e-02 -1.64803609e-01\n",
      "    -2.12901801e-01  4.19660704e-03 -1.26840204e-01  4.15023416e-02\n",
      "     8.86284262e-02 -1.99085176e-01 -1.24151669e-01  1.21569611e-01\n",
      "     7.69723766e-03 -3.09206024e-02  2.45092034e-01  2.00448021e-01\n",
      "     2.66613066e-02  2.54793555e-01  9.96502712e-02 -6.83214590e-02\n",
      "    -5.71719632e-02  1.08105727e-01  3.75101529e-02  7.34993145e-02\n",
      "     1.87769700e-02 -3.42235379e-02  4.00928594e-02  4.59547900e-02\n",
      "    -1.73874035e-01 -1.71362698e-01  4.89776209e-02  4.70776595e-02]]\n",
      "\n",
      "  [[ 3.44630480e-02 -9.92475003e-02  2.99375877e-02  8.33420008e-02\n",
      "     4.49064746e-02 -1.49058908e-01  5.50978892e-02  6.60832077e-02\n",
      "     2.32977599e-01  7.31615126e-02  2.14164751e-03 -1.44257611e-02\n",
      "     1.45090342e-01 -3.63579728e-02  3.40584815e-02 -2.97055006e-01\n",
      "     1.04762893e-02 -5.00698388e-02 -1.22043334e-01  7.81653523e-02\n",
      "    -1.11706614e-01 -4.65198793e-02 -1.67625144e-01  3.42913978e-02\n",
      "     7.77974585e-03  1.05774095e-02  8.00729170e-02 -3.11838146e-02\n",
      "    -1.01873606e-01  2.46938974e-01 -1.53508961e-01 -1.08950160e-01]\n",
      "   [ 5.78712486e-02 -1.82177320e-01  1.24195509e-01  1.40855342e-01\n",
      "    -6.00620806e-02 -8.52740034e-02  6.06905036e-02  1.18893154e-01\n",
      "    -2.97010183e-01 -7.73954466e-02  1.60338014e-01  1.84506267e-01\n",
      "     4.25939541e-03  5.60656786e-02 -2.54272483e-02 -1.09865651e-01\n",
      "    -4.54280600e-02 -3.83045375e-02 -1.20380610e-01 -2.87889242e-01\n",
      "     2.32371002e-01  9.51144174e-02  1.72985625e-03  1.15298800e-01\n",
      "    -9.83023420e-02 -3.18383165e-02 -7.63680786e-02  1.94017276e-01\n",
      "    -1.78429764e-02  1.51983753e-01 -2.56627947e-01  3.97696272e-02]\n",
      "   [-3.57663035e-02  8.73212814e-02  2.27536634e-01  1.63207073e-02\n",
      "    -9.48414654e-02  1.26933843e-01  1.50978744e-01  1.47128358e-01\n",
      "    -5.13798147e-02  4.29334752e-02  2.45472398e-02 -2.57281121e-02\n",
      "    -1.70376569e-01  6.53720796e-02 -1.06142573e-01 -4.98497561e-02\n",
      "    -1.36391118e-01  2.28285771e-02  2.28696428e-02  2.67573297e-02\n",
      "    -2.90392756e-01  1.04066819e-01  1.00621812e-01  1.40795946e-01\n",
      "     1.93980694e-01  1.10691130e-01  6.85963333e-02  3.77766006e-02\n",
      "    -1.97281390e-01 -8.92092511e-02 -4.61347401e-02  1.28294632e-01]]\n",
      "\n",
      "  [[ 3.39423902e-02  1.88790277e-01 -4.86870408e-02  8.46434981e-02\n",
      "     7.55338073e-02 -1.37169048e-01 -2.19556749e-01  1.91723526e-01\n",
      "     1.10421330e-01  2.95307010e-01 -1.83826789e-01  1.88766226e-01\n",
      "    -1.03957117e-01 -1.18299304e-02 -9.48219895e-02 -2.07093470e-02\n",
      "    -1.98437616e-01  4.60167136e-03 -1.37312844e-01  8.19882527e-02\n",
      "    -5.66977486e-02  5.10458313e-02 -1.46230683e-01  2.91178882e-01\n",
      "    -5.13586625e-02 -1.81439146e-01  1.17899090e-01 -1.91636622e-01\n",
      "     3.92747410e-02  1.11542471e-01 -8.12425315e-02  6.67612031e-02]\n",
      "   [ 6.12619072e-02  2.15803042e-01 -4.98801842e-02  1.96116753e-02\n",
      "     8.54768679e-02 -2.99529489e-02 -1.51909053e-01  2.26254389e-01\n",
      "    -2.12076187e-01  4.81199920e-02  2.40814015e-01  2.32654605e-02\n",
      "    -2.29904093e-02 -2.32394934e-01 -2.21431404e-01  1.19005196e-01\n",
      "    -2.27769911e-01  1.47490636e-01 -2.15310648e-01  1.66148767e-01\n",
      "     2.62577772e-01 -8.92035738e-02 -3.87498140e-02  1.98319018e-01\n",
      "     1.22269541e-01 -6.65000677e-02 -1.21961236e-01  1.30398870e-01\n",
      "    -9.16899368e-02  2.04717778e-02  5.79624660e-02 -1.13900028e-01]\n",
      "   [-2.68749744e-01  2.40410701e-03  8.75668898e-02  1.69440061e-01\n",
      "     6.30334094e-02  1.30973965e-01 -1.97317854e-01  9.27700922e-02\n",
      "     9.36104953e-02  1.30882248e-01  1.14395648e-01  1.52749449e-01\n",
      "    -2.72107590e-02 -1.23172030e-02 -2.56309122e-01  1.16178207e-01\n",
      "    -9.77041498e-02 -1.29841074e-01  1.52752757e-01 -6.53788000e-02\n",
      "    -1.22170456e-01 -1.93535149e-01  1.93364516e-01  1.87849566e-01\n",
      "     2.38950402e-01  1.67230293e-01  2.11229771e-02  6.74446225e-02\n",
      "    -1.07475691e-01 -2.31342837e-01 -6.73363432e-02  3.63022164e-02]]]\n",
      "\n",
      "\n",
      " [[[-1.47999346e-01 -1.31604776e-01  1.25868961e-01 -1.13325253e-01\n",
      "     3.30674738e-01 -1.93512350e-01 -1.70301646e-01 -2.77100444e-01\n",
      "     6.50886893e-02 -3.26797962e-01 -5.33020198e-02  6.28743768e-02\n",
      "     1.28117338e-01 -2.82126609e-02 -1.41519969e-02 -1.34296939e-01\n",
      "    -1.79336816e-01 -1.43836230e-01  1.07167907e-01 -1.35390535e-01\n",
      "     1.11505240e-01  2.25457281e-01 -1.97477005e-02 -5.01845293e-02\n",
      "     1.66132197e-01 -6.04628064e-02 -1.50849849e-01  6.61254022e-03\n",
      "    -1.83449492e-01 -7.04504224e-03 -1.27243688e-02  1.24825230e-02]\n",
      "   [ 1.89301930e-03 -1.05740339e-01 -1.21613860e-01  3.92670222e-02\n",
      "     2.59387583e-01 -1.80416424e-02  7.90023953e-02  4.32334691e-02\n",
      "    -8.94263089e-02 -1.25157200e-02 -2.42768750e-01  1.42196536e-01\n",
      "    -1.51335880e-01  2.28042603e-01 -9.41977836e-03 -1.71659470e-01\n",
      "    -1.65280759e-01 -2.17959166e-01  1.10991113e-01 -1.46988660e-01\n",
      "     2.46021807e-01  1.63062409e-01  2.68187579e-02 -7.82027841e-02\n",
      "    -1.90338671e-01  1.57741472e-01 -9.32087898e-02  4.57290560e-02\n",
      "    -1.50296181e-01 -6.47088513e-02 -7.36795589e-02  2.87186474e-01]\n",
      "   [ 2.44361430e-01  6.21170104e-02  4.31273319e-02 -2.72878110e-01\n",
      "     1.20912150e-01  2.13195756e-01  1.12547958e-02 -8.97158235e-02\n",
      "     9.79546607e-02 -5.32053672e-02 -8.09509680e-02  1.32471576e-01\n",
      "    -4.67508063e-02  7.29921088e-02  1.82572216e-01 -8.22982788e-02\n",
      "    -9.66082960e-02 -8.20638463e-02 -1.38940671e-02  1.19005488e-02\n",
      "    -1.27849758e-01  2.91303188e-01 -3.10348086e-02 -2.32415602e-01\n",
      "     6.71456903e-02 -7.08407089e-02 -1.22496009e-01 -1.34442106e-01\n",
      "    -2.53830045e-01  1.39479354e-01  6.34995624e-02  6.84109107e-02]]\n",
      "\n",
      "  [[-1.27217740e-01 -1.32538199e-01  2.31340870e-01  1.15719423e-01\n",
      "    -1.91695690e-01  1.02325194e-01  1.78715095e-01 -2.19838589e-01\n",
      "     1.29020691e-01 -1.00856565e-01 -1.66608423e-01  4.44329157e-02\n",
      "     2.70316958e-01  8.53715166e-02  9.64839309e-02  1.59660116e-01\n",
      "    -1.32456338e-02  5.51509485e-02  3.75726850e-05 -1.20689347e-01\n",
      "     9.19554010e-02 -1.85887605e-01 -1.05389684e-01 -1.64447084e-01\n",
      "     2.82456838e-02 -2.38862947e-01  2.34887943e-01 -2.23052260e-02\n",
      "    -9.17413384e-02 -8.84040669e-02  4.80510816e-02 -2.43954420e-01]\n",
      "   [-2.82677263e-01 -7.82546848e-02  1.55452862e-01 -4.81752492e-03\n",
      "    -2.82698780e-01  5.53380884e-02  4.97695267e-01  8.67247283e-02\n",
      "    -2.23059133e-01  2.05163844e-02 -2.90844321e-01  8.68395045e-02\n",
      "     1.55678287e-01  1.02642074e-01 -1.45426869e-01  5.85231334e-02\n",
      "    -1.47775367e-01 -2.09589694e-02 -9.81884077e-02 -1.61672562e-01\n",
      "     1.52099624e-01 -2.16578037e-01 -1.96812943e-01 -1.53487191e-01\n",
      "    -4.09571439e-01 -6.90298062e-03  1.81045040e-01  1.03711151e-01\n",
      "    -1.00367881e-01 -1.44079193e-01  2.01385971e-02 -2.28825629e-01]\n",
      "   [-2.23476976e-01 -4.52880263e-02  1.88227296e-01  2.20407918e-02\n",
      "    -1.93513319e-01  2.99769253e-01  3.69317643e-02  1.05480455e-01\n",
      "    -1.07351601e-01 -3.41060273e-02 -1.58072673e-02 -1.46710008e-01\n",
      "     3.02144557e-01 -9.99530926e-02 -2.46953517e-02  4.15149983e-03\n",
      "     8.38334858e-02 -1.70790385e-02 -4.60196510e-02  1.18174501e-01\n",
      "    -2.34989092e-01 -3.23398858e-02 -2.42441490e-01 -2.73351550e-01\n",
      "    -1.32283986e-01  6.43718466e-02  2.78759778e-01 -2.29834452e-01\n",
      "    -1.91431791e-01 -1.49226919e-01  1.05735086e-01 -1.87276781e-01]]\n",
      "\n",
      "  [[ 3.37488383e-01 -6.08298145e-02 -1.81102734e-02  1.14867976e-02\n",
      "    -1.43781841e-01 -4.36736707e-04  6.59410730e-02 -2.10471019e-01\n",
      "     6.84935972e-02  2.13512555e-01 -5.94990887e-02 -3.64758894e-02\n",
      "    -5.41721620e-02 -8.57568979e-02 -1.18809454e-01  3.06803808e-02\n",
      "    -2.27766521e-02  2.41453536e-02  1.40058488e-01  9.31081995e-02\n",
      "    -4.05011699e-02 -7.91798234e-02 -1.94434881e-01 -3.65737043e-02\n",
      "     2.97513511e-02 -1.54138669e-01 -7.28899390e-02 -7.14380741e-02\n",
      "     8.43305364e-02  1.33576512e-01 -3.63619416e-03  2.91085839e-01]\n",
      "   [ 1.94825828e-01 -1.18959233e-01 -1.03371918e-01  1.56514823e-01\n",
      "     3.97124775e-02 -1.90947857e-02  9.82384160e-02  9.19901207e-02\n",
      "     1.27929538e-01  8.90840963e-02 -1.80854741e-02 -1.81178629e-01\n",
      "     6.00633956e-02 -3.27210069e-01 -1.05772771e-01  2.47837678e-01\n",
      "    -1.27885625e-01  5.56624569e-02 -1.23199999e-01  2.58173764e-01\n",
      "     1.91107802e-02 -4.28103842e-02 -1.31280005e-01 -3.25068012e-02\n",
      "    -1.70492932e-01  9.03631672e-02 -5.01036271e-02 -9.61587057e-02\n",
      "     1.79328382e-01  1.10289685e-01 -6.42533973e-02 -9.47342254e-03]\n",
      "   [ 8.43799189e-02 -1.21460393e-01 -2.97580026e-02  1.69838592e-01\n",
      "     1.26923829e-01  1.03801042e-01  6.04317598e-02  3.76035050e-02\n",
      "    -6.43172711e-02  2.06150606e-01  9.02005807e-02  3.22872214e-02\n",
      "     1.45311773e-01 -1.40990317e-01 -2.44461104e-01 -5.71252964e-02\n",
      "    -1.20429546e-01 -9.61825922e-02  1.85641319e-01  2.91019320e-01\n",
      "    -3.50119025e-02 -1.86867058e-01  1.54014733e-02  7.60941803e-02\n",
      "    -2.05329712e-02  1.52020901e-01  1.17188103e-01 -6.95522055e-02\n",
      "     1.28193885e-01  2.10372321e-02  2.46580571e-01  1.31304815e-01]]]\n",
      "\n",
      "\n",
      " [[[-6.73164874e-02  9.43434909e-02  2.38029480e-01 -1.71821862e-01\n",
      "     5.81838116e-02 -2.08798364e-01 -1.81503780e-02 -1.75381973e-01\n",
      "    -1.82855055e-02 -1.72066271e-01  3.01375002e-01 -2.76328139e-02\n",
      "     1.06137231e-01  1.89248338e-01  1.55742150e-02  1.94814220e-01\n",
      "    -7.77102858e-02 -2.35559285e-01 -9.84801725e-02  1.68795750e-01\n",
      "    -4.31209942e-03  1.66101381e-01  3.94586951e-01 -8.81305784e-02\n",
      "     1.52180552e-01  4.97167110e-02 -1.09906152e-01  1.58438846e-01\n",
      "     1.14402309e-01 -1.18937895e-01 -1.28955217e-02 -9.54674631e-02]\n",
      "   [-6.49817884e-02  2.49717638e-01 -1.18914828e-01 -1.78937063e-01\n",
      "    -8.91434960e-03  1.07519202e-01 -1.44227505e-01 -7.15929866e-02\n",
      "     1.43606320e-01 -1.09574698e-01 -1.38848245e-01 -9.98581573e-02\n",
      "    -1.63963899e-01  3.16010982e-01  1.36722431e-01 -1.65692732e-01\n",
      "     1.86714247e-01 -2.82862604e-01  8.47663581e-02 -1.43700108e-01\n",
      "     6.81027919e-02 -1.21502630e-01  3.83425923e-03  1.09393604e-01\n",
      "    -7.46299848e-02  2.27283873e-02 -8.24278891e-02 -1.83725759e-01\n",
      "    -1.96947828e-02  1.98093951e-01  2.23173112e-01  2.05951765e-01]\n",
      "   [ 1.49190724e-01  7.81498924e-02 -1.45246506e-01 -2.33438745e-01\n",
      "     1.51281327e-01  5.52104153e-02 -1.77195236e-01 -3.08217034e-02\n",
      "    -1.96641415e-01 -5.76390661e-02 -6.46750703e-02 -1.45777449e-01\n",
      "     1.05747171e-01 -3.57286930e-02  1.88276172e-01  9.87504348e-02\n",
      "     2.39309102e-01 -3.44213724e-01 -2.20197529e-01 -4.78828140e-03\n",
      "     8.16221312e-02  1.11249074e-01 -9.26977396e-02 -1.33598745e-01\n",
      "    -2.91239787e-02 -5.16461879e-02  1.58692896e-01 -2.00713411e-01\n",
      "     1.53003260e-01  1.78642213e-01  2.71092802e-01  2.53752694e-02]]\n",
      "\n",
      "  [[ 3.45045999e-02  5.73703162e-02  1.40900567e-01  1.44231552e-02\n",
      "    -1.14421867e-01 -1.33803725e-01 -3.55743580e-02 -2.64608085e-01\n",
      "    -1.59106717e-01  3.99536602e-02  1.86484292e-01 -1.93483338e-01\n",
      "     3.18530612e-02 -9.22592878e-02  1.65434957e-01  2.48729020e-01\n",
      "     1.04073912e-01 -1.39251515e-01 -2.05109105e-01  3.40469144e-02\n",
      "    -7.17415139e-02 -1.50277212e-01  3.02617103e-01  1.70657616e-02\n",
      "    -1.13772824e-01 -8.02136511e-02  1.51936606e-01  1.45498514e-01\n",
      "     1.10677741e-01 -1.44753247e-01 -7.46629611e-02  7.27213472e-02]\n",
      "   [-1.73246786e-01  2.79916912e-01 -1.35514095e-01 -1.54387146e-01\n",
      "    -2.42208600e-01 -8.58248025e-02  1.78646505e-01  1.08497627e-02\n",
      "     5.84345497e-02  3.96515541e-02 -1.29375562e-01 -2.24661916e-01\n",
      "    -3.07273746e-01 -1.58667803e-01  1.37318879e-01 -5.70558496e-02\n",
      "     1.80953771e-01 -5.02406321e-02  3.55230980e-02 -1.75807387e-01\n",
      "    -9.90951210e-02 -1.94409490e-01 -2.02351939e-02 -6.13861047e-02\n",
      "    -2.39485979e-01 -5.46630882e-02 -1.67633548e-01 -2.01898471e-01\n",
      "     1.89369261e-01 -1.52549759e-01  5.80141433e-02  4.17849235e-02]\n",
      "   [ 1.10628165e-01 -3.78793888e-02 -3.30479816e-02 -2.12802157e-01\n",
      "    -1.33836837e-02  1.93986550e-01  2.70069111e-02 -1.24140561e-01\n",
      "     1.32124379e-01 -1.12209551e-01  1.30836712e-02 -2.00644694e-02\n",
      "    -1.52099580e-01 -1.14564948e-01 -8.63288566e-02  4.70716767e-02\n",
      "     1.46527007e-01 -2.41049260e-01 -2.97627896e-01  1.78163685e-02\n",
      "     1.14870265e-01 -1.31063953e-01  9.15174410e-02 -1.18581928e-01\n",
      "     1.09383911e-01  3.56205814e-02 -1.84515063e-02  6.29036501e-02\n",
      "     2.17221886e-01  2.40979120e-01 -4.63610375e-03 -8.56770650e-02]]\n",
      "\n",
      "  [[ 9.30605978e-02 -1.77946582e-01  1.64997280e-01  1.76558554e-01\n",
      "    -6.42040893e-02 -1.04135722e-01  9.07714665e-02 -1.84185758e-01\n",
      "    -1.50485575e-01  2.11069912e-01  1.40724465e-01 -2.37698928e-01\n",
      "    -1.49263635e-01 -1.37954593e-01  1.74489215e-01 -9.23538432e-02\n",
      "     1.19696632e-01  1.96367040e-01  2.12259203e-01 -1.52600542e-01\n",
      "    -7.04700947e-02  1.58071607e-01  1.33276135e-01 -6.71701208e-02\n",
      "    -1.15650982e-01 -1.57257840e-01 -1.55629143e-01  8.18374231e-02\n",
      "     1.05709821e-01 -1.59310713e-01  1.12102583e-01  1.65308699e-01]\n",
      "   [-6.26165122e-02  1.51046455e-01  2.25967895e-02  1.74591288e-01\n",
      "     1.44950628e-01 -6.46439344e-02  1.63660124e-01  1.12809785e-01\n",
      "     6.36523515e-02 -2.68660132e-02  4.50292863e-02 -1.65884510e-01\n",
      "    -1.15338922e-01 -1.21615805e-01 -1.37816332e-02 -4.63307537e-02\n",
      "     1.46017402e-01  2.42440537e-01  1.93446383e-01  4.83676158e-02\n",
      "    -1.28360540e-01  9.56609566e-03  1.10828534e-01 -1.43353179e-01\n",
      "     7.12993965e-02  2.67385803e-02 -2.38998577e-01 -1.19367115e-01\n",
      "     1.28991395e-01 -1.02400057e-01  1.36623040e-01 -1.87392935e-01]\n",
      "   [-3.51831652e-02 -2.20154315e-01 -1.34802818e-01  7.42220953e-02\n",
      "     1.37494102e-01  5.21294773e-02 -6.07264116e-02 -1.20473867e-02\n",
      "     1.11813441e-01  8.15560296e-02  1.00976802e-01 -8.37345123e-02\n",
      "     1.41416401e-01 -1.65281028e-01 -7.22569898e-02 -2.69878000e-01\n",
      "     1.22090198e-01  1.58772260e-01  1.63322479e-01  1.18217841e-01\n",
      "     7.06545487e-02  7.32397437e-02  3.20173660e-03  1.35289848e-01\n",
      "     1.50912227e-02  1.67069137e-02  1.15796298e-01  2.34033063e-01\n",
      "     2.54206449e-01  1.00260101e-01  2.34363362e-01 -1.79998666e-01]]]]\n",
      "  Param 1 wieight: [-0.03104683 -0.05664378 -0.01743385 -0.01626933 -0.04382552  0.00095323\n",
      "  0.00486994 -0.01118289 -0.05737542 -0.01611796  0.07341599 -0.01644105\n",
      " -0.12279225  0.05645571 -0.0337188   0.01167611  0.0295548  -0.01335975\n",
      " -0.13234009  0.01786577 -0.05754707 -0.13508393 -0.01476652  0.00096925\n",
      "  0.02176993  0.02824113  0.01200188  0.03461488  0.03628847  0.0554832\n",
      " -0.00648493  0.0526071 ]\n",
      "Layer 1: batch_normalization\n",
      "  Param 0 wieight: [1.5018655  0.84149784 0.5602178  0.42604604 1.6863775  0.5959035\n",
      " 0.74046844 0.76742953 0.9916747  1.0121421  1.1842916  0.92498136\n",
      " 0.96407825 0.82682556 0.698324   0.9305272  0.8432131  0.8827056\n",
      " 1.2708141  0.76031435 0.6839215  1.2201309  1.1212287  0.8964492\n",
      " 0.868611   0.5857143  0.51157504 0.87775433 1.0157076  1.1118636\n",
      " 0.6719112  1.3722513 ]\n",
      "  Param 1 wieight: [ 0.7605062   0.13615789 -0.239818    0.06594712  0.64948785 -0.17648722\n",
      " -0.3874747  -0.16314103  0.3043538  -0.13915321  0.56447905  0.10075094\n",
      "  0.579384   -0.3576211  -0.07786267  0.7587063  -0.15988235 -0.37551117\n",
      "  0.62594414  0.17159037 -0.13144428  0.43345016  0.08014477 -0.08299067\n",
      " -0.38705164 -0.06881714 -0.10478891  0.12030267  0.08598603  0.45673078\n",
      " -0.4026878   0.838244  ]\n",
      "  Param 2 wieight: [-0.02863584 -0.05758416  0.32892984  0.01678684 -0.04172453 -0.02504653\n",
      "  0.31090206 -0.13989024 -0.06258313 -0.014195    0.052965    0.01133494\n",
      " -0.10830539 -0.18304382 -0.02117779  0.0243659  -0.16721238 -0.38500935\n",
      " -0.1309516   0.02074888 -0.04140577 -0.14658278 -0.01082171 -0.0136492\n",
      " -0.21682069  0.13293155 -0.03953845  0.01731555  0.02629185  0.04326918\n",
      "  0.146207    0.05474383]\n",
      "  Param 3 wieight: [0.00417911 0.00674165 0.03056966 0.04091231 0.00933103 0.03096293\n",
      " 0.02977775 0.04023542 0.0035382  0.04104844 0.00937905 0.05215814\n",
      " 0.00680726 0.05019601 0.03377412 0.0014864  0.04120734 0.06350887\n",
      " 0.00661199 0.01446575 0.006172   0.01880197 0.01466476 0.03492099\n",
      " 0.02151331 0.01847743 0.01055123 0.00520575 0.04391343 0.00202065\n",
      " 0.04821771 0.00322828]\n",
      "Layer 2: re_lu (No weights)\n",
      "Layer 3: conv2d_1\n",
      "  Param 0 wieight: [[[[-1.60662279e-01 -1.40874937e-01 -2.13747378e-02 ... -1.64743796e-01\n",
      "     2.69508902e-02  9.51032713e-03]\n",
      "   [-7.61015490e-02 -1.14901245e-01  2.49820221e-02 ...  2.59222537e-01\n",
      "    -5.39691262e-02 -8.25190172e-02]\n",
      "   [ 5.92069477e-02 -3.25843930e-01  9.45068598e-02 ... -2.16194406e-01\n",
      "    -1.25081867e-01  3.00356969e-02]\n",
      "   ...\n",
      "   [-2.46010438e-01 -1.51565030e-01 -1.54085487e-01 ...  2.11878177e-02\n",
      "    -1.00511618e-01  7.98924416e-02]\n",
      "   [-7.52337426e-02  1.17283270e-01  5.30114695e-02 ...  1.49484068e-01\n",
      "     8.82404856e-03 -3.47287171e-02]\n",
      "   [ 1.16472580e-01 -8.08115769e-03 -1.00961030e-01 ... -3.35934944e-02\n",
      "    -1.18761875e-01  1.06121838e-01]]\n",
      "\n",
      "  [[ 3.50742266e-02  6.53972775e-02  1.78710490e-01 ... -4.91229594e-02\n",
      "    -5.71733713e-02  3.78822014e-02]\n",
      "   [-6.91541508e-02 -1.04677202e-02 -1.03643481e-02 ...  1.50935248e-01\n",
      "     7.69523531e-02 -1.20457411e-01]\n",
      "   [ 4.34511676e-02 -1.57239735e-01 -7.92841688e-02 ... -1.28193542e-01\n",
      "    -8.90270546e-02  1.15091344e-02]\n",
      "   ...\n",
      "   [-1.95308596e-01 -6.01223595e-02  1.73330292e-01 ... -2.28516757e-02\n",
      "    -1.00674681e-01  8.32921490e-02]\n",
      "   [-4.35868241e-02  1.58462718e-01  5.08117713e-02 ... -1.03346370e-01\n",
      "     7.28807151e-02  7.64751658e-02]\n",
      "   [ 6.56886324e-02 -2.43239515e-02  1.15472049e-01 ...  1.75524041e-01\n",
      "     5.82429804e-02  8.48575402e-03]]\n",
      "\n",
      "  [[-1.02433180e-02  2.32866600e-01 -2.25548789e-01 ... -6.12925887e-02\n",
      "    -2.54665077e-01  7.74661824e-02]\n",
      "   [ 1.17635548e-01 -5.80422580e-03 -9.25595239e-02 ...  9.74141881e-02\n",
      "    -1.15988813e-02 -8.59518722e-03]\n",
      "   [ 3.86568233e-02 -1.90830588e-01  7.28286132e-02 ... -2.42750034e-01\n",
      "    -5.57691045e-02  1.25336081e-01]\n",
      "   ...\n",
      "   [-1.65238723e-01 -1.47008955e-01  5.15349545e-02 ... -1.21468112e-01\n",
      "    -5.66760488e-02  8.70202929e-02]\n",
      "   [-1.73759495e-03  2.17017785e-01 -1.66029707e-01 ...  2.50080079e-02\n",
      "     7.26933964e-03 -8.99464414e-02]\n",
      "   [ 1.40853375e-01 -4.09765579e-02 -5.45849279e-02 ...  2.00431839e-01\n",
      "     7.31000975e-02 -4.54130396e-02]]]\n",
      "\n",
      "\n",
      " [[[ 3.81423309e-02 -1.30265266e-01 -1.14593230e-01 ...  1.08337514e-01\n",
      "     2.36071721e-01 -1.62646584e-02]\n",
      "   [-3.52927670e-02 -2.28799321e-02  3.89879309e-02 ...  2.43655875e-01\n",
      "    -9.50625986e-02 -1.52994752e-01]\n",
      "   [ 9.85280424e-02 -8.22016895e-02  6.70029223e-02 ... -1.36514872e-01\n",
      "    -5.75757734e-02  7.68259689e-02]\n",
      "   ...\n",
      "   [-1.64202049e-01 -2.21938208e-01 -5.07359467e-02 ... -3.49222496e-02\n",
      "    -1.07150048e-01  2.31807098e-01]\n",
      "   [-1.29719600e-02 -1.28261641e-01 -1.04792789e-01 ...  6.35279268e-02\n",
      "     1.46135420e-01 -1.66491717e-01]\n",
      "   [ 2.24877104e-01  2.16290757e-01 -6.99110627e-02 ... -1.18037738e-01\n",
      "    -8.45189542e-02 -1.18489929e-01]]\n",
      "\n",
      "  [[ 4.81353700e-02  1.17448777e-01  2.77440548e-01 ... -3.45578581e-01\n",
      "    -3.92456539e-02 -3.37988026e-02]\n",
      "   [-9.44493115e-02  1.14838541e-01  1.20413397e-02 ... -9.92591530e-02\n",
      "    -1.01759210e-01 -1.30011484e-01]\n",
      "   [ 1.25481263e-02 -4.06755358e-02 -4.81220782e-02 ...  9.48221982e-03\n",
      "     1.91376861e-02 -1.75736845e-02]\n",
      "   ...\n",
      "   [-8.93504992e-02 -2.08302602e-01  4.25337814e-02 ...  1.87795889e-02\n",
      "    -6.14269152e-02  2.35160112e-01]\n",
      "   [-1.28177494e-01 -1.38018906e-01 -2.64856895e-03 ... -2.01333240e-02\n",
      "     7.05552101e-02 -8.69308114e-02]\n",
      "   [ 8.97027403e-02  9.49974582e-02  2.13143289e-01 ... -1.40639022e-01\n",
      "    -5.81556149e-02 -1.89773709e-01]]\n",
      "\n",
      "  [[ 7.00572133e-02  4.16132109e-03 -1.86130121e-01 ... -1.46296114e-01\n",
      "    -2.77782321e-01 -5.92243299e-03]\n",
      "   [-6.17408566e-02  1.13769844e-01  7.09366724e-02 ... -1.16995208e-01\n",
      "     1.55837044e-01 -6.17109165e-02]\n",
      "   [-6.32520765e-02 -5.02861887e-02  7.61759281e-02 ... -5.81502467e-02\n",
      "    -1.87879652e-01 -1.03133425e-01]\n",
      "   ...\n",
      "   [ 3.80810052e-02 -1.15772188e-01 -9.58543941e-02 ...  4.36596684e-02\n",
      "    -8.31276625e-02  2.89055347e-01]\n",
      "   [-2.14291528e-01 -4.35638167e-02 -1.53797939e-01 ... -2.52635553e-02\n",
      "     5.87747656e-02 -1.40936315e-01]\n",
      "   [-9.29504633e-02 -2.39174608e-02 -1.48134917e-01 ...  2.33937845e-01\n",
      "     7.01400116e-02 -1.79501936e-01]]]\n",
      "\n",
      "\n",
      " [[[ 1.40264973e-01  8.47324058e-02 -1.52214974e-01 ...  3.62162709e-01\n",
      "     1.42948836e-01 -4.47051078e-02]\n",
      "   [-9.51566771e-02  1.63340896e-01  1.09024957e-01 ... -1.73735157e-01\n",
      "    -1.82595372e-01 -9.96133238e-02]\n",
      "   [-1.59398034e-01 -1.34488314e-01  1.63032532e-01 ... -8.19571838e-02\n",
      "    -1.01074219e-01 -1.52248099e-01]\n",
      "   ...\n",
      "   [ 1.62571706e-02 -7.98248202e-02  5.12655899e-02 ...  1.21129520e-01\n",
      "     4.92636599e-02  1.45337090e-01]\n",
      "   [-2.73028702e-01 -1.89197212e-01 -6.13637790e-02 ... -4.15504500e-02\n",
      "     2.39623915e-02 -4.42206115e-01]\n",
      "   [ 4.06645015e-02  1.98015094e-01  4.93870080e-02 ... -2.83701062e-01\n",
      "    -1.43615454e-01 -1.43689632e-01]]\n",
      "\n",
      "  [[ 3.17174681e-02 -3.73904966e-02  2.67403454e-01 ...  9.68575850e-02\n",
      "    -1.17139705e-01  1.39308833e-02]\n",
      "   [-1.50723308e-01 -6.55621197e-03 -5.90654723e-02 ... -1.93553641e-01\n",
      "    -2.15229124e-01 -4.44516800e-02]\n",
      "   [-9.78465155e-02  8.50045681e-03 -4.37493287e-02 ... -4.81265411e-02\n",
      "    -1.47553086e-01 -7.14759678e-02]\n",
      "   ...\n",
      "   [ 1.15357943e-01 -9.41479765e-03 -9.97493509e-03 ...  1.24801338e-01\n",
      "    -1.17622167e-02  1.52621135e-01]\n",
      "   [-2.30331734e-01  3.18937786e-02  1.03427999e-01 ... -4.60533202e-02\n",
      "    -1.60246845e-02 -4.01121438e-01]\n",
      "   [ 7.21251220e-02  2.78015416e-02  1.07478954e-01 ... -1.86531529e-01\n",
      "    -1.92574739e-01 -1.06766811e-02]]\n",
      "\n",
      "  [[ 5.53173088e-02  3.07698231e-02 -2.47208998e-01 ... -1.33801914e-05\n",
      "    -2.95633554e-01  2.14093477e-02]\n",
      "   [ 7.73479193e-02  1.05985738e-01 -2.08444685e-01 ... -1.96658805e-01\n",
      "     3.80175747e-02  1.45275816e-01]\n",
      "   [-1.50174901e-01 -3.30675319e-02  1.66400224e-01 ... -1.75267577e-01\n",
      "    -1.05291411e-01 -1.73531070e-01]\n",
      "   ...\n",
      "   [ 6.36245012e-02 -7.22241923e-02 -8.94479081e-02 ...  9.49260443e-02\n",
      "     2.03876179e-02  1.30243480e-01]\n",
      "   [-3.26997131e-01  8.11152533e-02  1.91202387e-02 ... -1.08485833e-01\n",
      "     1.09646879e-01 -4.14861470e-01]\n",
      "   [-1.18587665e-01 -6.13388829e-02 -3.18654895e-01 ...  1.01424135e-01\n",
      "     1.99947646e-03  1.38119254e-02]]]]\n",
      "  Param 1 wieight: [-0.00136053  0.00043606  0.0034123  -0.00944005  0.00220942  0.00186362\n",
      "  0.00371501  0.00596957 -0.00279452 -0.00605462  0.00260803 -0.0019377\n",
      " -0.00047173  0.00042999 -0.00078333  0.01088637  0.01193489 -0.00044668\n",
      " -0.00661847  0.00115204 -0.00715749  0.00287449  0.00743868 -0.00899913\n",
      " -0.00020426 -0.00417891 -0.00105724 -0.00195886  0.00586483  0.00495032\n",
      " -0.00109464 -0.00270939]\n",
      "Layer 4: batch_normalization_1\n",
      "  Param 0 wieight: [0.8615341  0.8113552  0.8676302  0.9499138  0.9599943  0.88142586\n",
      " 0.9936433  0.93487    0.92795074 0.89631176 0.93497807 0.84850556\n",
      " 0.9353105  0.8557646  0.9407582  0.9107734  0.9523377  1.0106678\n",
      " 0.93753344 1.0184861  0.96878856 0.9152848  0.93311524 0.9909259\n",
      " 0.98217607 0.8817088  0.9604687  1.0728031  0.8693581  1.0702766\n",
      " 1.0886009  0.9377039 ]\n",
      "  Param 1 wieight: [-0.24351686 -0.25717106 -0.34180814 -0.46807528 -0.41100445 -0.21110019\n",
      " -0.53318924 -0.36782947 -0.2673845  -0.35277456 -0.4593946  -0.3476082\n",
      " -0.29316473 -0.28926474 -0.34557554 -0.5505105  -0.4529664  -0.47371805\n",
      " -0.5166256  -0.56752795 -0.3803589  -0.38422522 -0.35968438 -0.5971155\n",
      " -0.3243478  -0.37918258 -0.46148953 -0.5106841  -0.28105858 -0.35041794\n",
      " -0.4888243  -0.37808543]\n",
      "  Param 2 wieight: [ 2.2026858   0.00835543 -2.0305767  -0.6908494  -2.4770987   3.7238154\n",
      " -0.9541909  -1.9231098  -0.94044846 -1.3689247  -0.9408215  -0.90649813\n",
      " -0.6402362  -0.06659707 -0.9218067  -0.35899016 -1.2032878  -0.8442079\n",
      " -0.70202076 -1.3713499  -0.3997275  -0.6087054  -0.3737947  -1.6616023\n",
      " -0.96117055 -1.5506562  -0.30839342 -2.09934    -1.4633915  -1.3369713\n",
      " -3.2776005  -0.33156857]\n",
      "  Param 3 wieight: [3.825816  2.3671782 3.9627995 3.0708144 7.383601  3.9080806 1.7224005\n",
      " 4.679399  3.2958183 6.383636  5.7982116 5.9930854 7.6680355 5.5647497\n",
      " 4.634446  2.903184  2.4145322 2.6435902 2.6688085 3.4952137 4.7138224\n",
      " 2.3989909 6.057134  1.8595092 3.5738473 4.1505156 4.0465803 4.645957\n",
      " 3.324065  2.0713143 7.1835017 7.6903296]\n",
      "Layer 5: re_lu_1 (No weights)\n",
      "Layer 6: max_pooling2d (No weights)\n",
      "Layer 7: dropout (No weights)\n",
      "Layer 8: conv2d_2\n",
      "  Param 0 wieight: [[[[-0.11849815 -0.14223993 -0.01185019 ...  0.08199089 -0.01376978\n",
      "    -0.18850401]\n",
      "   [ 0.00844851 -0.07993437  0.00480291 ... -0.36317036 -0.04657498\n",
      "     0.00049696]\n",
      "   [-0.2075592  -0.24663699 -0.02906122 ...  0.15385824  0.00187349\n",
      "     0.05164964]\n",
      "   ...\n",
      "   [ 0.00112402  0.00170613 -0.02439144 ... -0.18960498 -0.3098163\n",
      "     0.12317676]\n",
      "   [ 0.06004023 -0.2151945  -0.00321711 ... -0.08502174 -0.04416654\n",
      "    -0.19214554]\n",
      "   [-0.06903844  0.03682599  0.03427815 ...  0.05097613 -0.10365252\n",
      "    -0.03474253]]\n",
      "\n",
      "  [[-0.04626434 -0.05157291  0.07001047 ... -0.06161404 -0.16230926\n",
      "     0.01005207]\n",
      "   [-0.05735453 -0.11614869  0.1265837  ... -0.2088742  -0.05343521\n",
      "     0.2939888 ]\n",
      "   [-0.13724682 -0.3789963   0.15526083 ...  0.00567565  0.21572986\n",
      "     0.10529333]\n",
      "   ...\n",
      "   [-0.02412076  0.03204286  0.00578919 ... -0.19323032 -0.46341327\n",
      "     0.18642908]\n",
      "   [-0.1405456  -0.15309554  0.08314981 ... -0.2780946   0.02296748\n",
      "     0.04318507]\n",
      "   [-0.00492325  0.08769663 -0.01027216 ...  0.14552006 -0.16772223\n",
      "     0.04019356]]\n",
      "\n",
      "  [[ 0.0596591  -0.06054919  0.04626166 ... -0.06177132 -0.14362471\n",
      "     0.10105003]\n",
      "   [-0.04661156 -0.16692074  0.17489867 ... -0.15979551  0.16215472\n",
      "     0.2697607 ]\n",
      "   [-0.01348232 -0.18245432  0.20589854 ...  0.08703862  0.0125327\n",
      "    -0.01325245]\n",
      "   ...\n",
      "   [ 0.06241028 -0.03965109 -0.15313609 ... -0.23725595 -0.22137944\n",
      "     0.19035865]\n",
      "   [ 0.04588293  0.06061286  0.05560913 ... -0.00265269  0.0222309\n",
      "     0.19393189]\n",
      "   [ 0.03995071 -0.04247592  0.03501818 ...  0.04024855 -0.20982984\n",
      "     0.13534825]]]\n",
      "\n",
      "\n",
      " [[[ 0.05437398 -0.07309297 -0.26218724 ... -0.09711335  0.019288\n",
      "    -0.21526788]\n",
      "   [ 0.09025751 -0.07313031  0.08221648 ... -0.23443    -0.04724319\n",
      "     0.01011002]\n",
      "   [-0.12234206 -0.34404382  0.01831688 ...  0.13303179 -0.00157139\n",
      "     0.09782367]\n",
      "   ...\n",
      "   [-0.07663754 -0.17086469  0.02331536 ... -0.1212101  -0.16588242\n",
      "    -0.08544806]\n",
      "   [ 0.09121995 -0.3002336  -0.28644344 ... -0.15469338 -0.03014076\n",
      "    -0.11705312]\n",
      "   [-0.0684269   0.01395323 -0.04075109 ...  0.07759733  0.06683936\n",
      "    -0.22300525]]\n",
      "\n",
      "  [[-0.12412834 -0.06345997 -0.01399022 ... -0.1437628  -0.2535382\n",
      "    -0.00887734]\n",
      "   [-0.0675597  -0.07698502 -0.03746815 ... -0.19376001 -0.15452224\n",
      "     0.30090696]\n",
      "   [-0.24133651 -0.41126007 -0.08371288 ...  0.15325575  0.01050665\n",
      "     0.08620996]\n",
      "   ...\n",
      "   [-0.11376959 -0.20918363 -0.03457574 ... -0.22946806 -0.3884523\n",
      "     0.07654549]\n",
      "   [-0.06752456 -0.32802477 -0.25882342 ... -0.2742216   0.11471167\n",
      "     0.03738557]\n",
      "   [-0.16618547 -0.01062361  0.17860438 ...  0.04597668 -0.07216052\n",
      "     0.04664915]]\n",
      "\n",
      "  [[-0.03768401  0.02964973  0.0779709  ... -0.21058613 -0.3019961\n",
      "     0.13417478]\n",
      "   [-0.08226617  0.1464365   0.07352924 ... -0.1980753  -0.01691937\n",
      "     0.15846798]\n",
      "   [-0.06362144 -0.12989995  0.14222856 ...  0.07633361  0.0061069\n",
      "     0.0183375 ]\n",
      "   ...\n",
      "   [ 0.09167333 -0.14668019 -0.03259155 ... -0.21702312 -0.06275441\n",
      "     0.14529493]\n",
      "   [ 0.014111   -0.1100296   0.01029986 ... -0.05680355  0.02123215\n",
      "     0.06216859]\n",
      "   [-0.09812649 -0.09687991  0.14430329 ... -0.03075036  0.03630708\n",
      "     0.1005526 ]]]\n",
      "\n",
      "\n",
      " [[[ 0.03629737 -0.08539642 -0.39826226 ... -0.15691574  0.15162523\n",
      "    -0.25957826]\n",
      "   [ 0.08880666  0.02427378 -0.05765326 ... -0.00674678  0.03083378\n",
      "    -0.1803215 ]\n",
      "   [-0.02352913  0.07655991  0.2428483  ...  0.17688076 -0.00820069\n",
      "    -0.01623159]\n",
      "   ...\n",
      "   [-0.06616435 -0.17813396  0.06734809 ... -0.07837405  0.05131152\n",
      "    -0.05498353]\n",
      "   [ 0.09308692 -0.01438331 -0.20067722 ...  0.00308187  0.03135522\n",
      "    -0.18761677]\n",
      "   [-0.0222102  -0.02035855 -0.06543668 ...  0.03979048 -0.01996481\n",
      "    -0.13501246]]\n",
      "\n",
      "  [[-0.01085776 -0.22352834 -0.2921197  ... -0.17404279 -0.1533215\n",
      "    -0.15056977]\n",
      "   [ 0.09030253  0.15896212 -0.09663619 ... -0.02338415 -0.12105499\n",
      "    -0.13683437]\n",
      "   [-0.08825981  0.0101266   0.14470205 ...  0.20222394  0.03855354\n",
      "    -0.01727703]\n",
      "   ...\n",
      "   [-0.09872495 -0.16595499  0.03874354 ... -0.116436   -0.08057152\n",
      "    -0.04225707]\n",
      "   [ 0.10642602 -0.1520106  -0.26962814 ... -0.20050944  0.23086797\n",
      "    -0.13555259]\n",
      "   [-0.04355331  0.0068269   0.07729109 ... -0.08126853 -0.12381742\n",
      "     0.13479738]]\n",
      "\n",
      "  [[-0.01847084 -0.05884685 -0.22384839 ... -0.16819029 -0.15051645\n",
      "    -0.09709986]\n",
      "   [ 0.03313908  0.19544098 -0.13107444 ... -0.00914924  0.05230011\n",
      "    -0.01107156]\n",
      "   [-0.02111274 -0.02734833  0.15144838 ...  0.18747605  0.02505128\n",
      "    -0.1411673 ]\n",
      "   ...\n",
      "   [-0.06217196  0.1109573   0.05147288 ... -0.06954069  0.15935649\n",
      "     0.00084824]\n",
      "   [ 0.10659733 -0.02440687 -0.09287222 ...  0.02094859  0.13295953\n",
      "    -0.16329844]\n",
      "   [-0.02253282 -0.0456358   0.11278167 ...  0.06731305 -0.0982105\n",
      "     0.02577998]]]]\n",
      "  Param 1 wieight: [-1.4063008e-03 -3.1325212e-04  2.0802447e-03  2.0802357e-04\n",
      " -2.6439452e-03 -3.5411974e-03 -8.9345896e-04 -3.1556183e-04\n",
      "  4.1991700e-03 -2.9529354e-03  1.6162670e-03 -8.7208714e-04\n",
      " -2.7546058e-03 -5.9868704e-04  1.9770474e-03  4.0115486e-03\n",
      "  4.7181540e-05  7.5342244e-04 -1.1732305e-03 -3.8747150e-03\n",
      " -1.5882729e-03 -3.0500160e-03  1.2851646e-03 -1.6581281e-03\n",
      "  2.6170543e-04  4.7263439e-04 -9.6055155e-04  4.0027993e-05\n",
      " -1.2456765e-03 -9.1105892e-04 -1.6408458e-03  8.4235915e-04\n",
      "  1.9726835e-03  2.2366641e-03  5.8923033e-04  1.3027133e-03\n",
      " -9.1115531e-04  8.4247859e-04  6.3905315e-03 -7.4867246e-04\n",
      " -2.6700245e-03  7.7780208e-04  3.7516418e-03  3.4837320e-03\n",
      "  1.7892312e-03 -1.4011975e-03 -1.3528696e-03  2.0552517e-03\n",
      " -6.3164649e-04 -8.0236758e-04  5.2048411e-04  6.1171077e-04\n",
      "  3.7031258e-03  3.5150785e-03 -7.4082031e-04  1.5662294e-03\n",
      "  2.8524280e-03  7.0916591e-03  7.7299512e-04 -2.0480726e-03\n",
      " -1.3449868e-03 -2.3955738e-03 -4.0635088e-04 -3.5972144e-03]\n",
      "Layer 9: batch_normalization_2\n",
      "  Param 0 wieight: [1.1876664  0.9870884  0.8755487  1.0754435  1.0547729  1.1264191\n",
      " 0.80689585 0.84442925 1.1980865  1.0612161  1.0126598  0.924191\n",
      " 1.1139057  1.175468   1.038816   1.1235038  1.0409663  0.9225531\n",
      " 0.98063064 0.9874035  1.0403157  0.9359786  0.85806626 1.0154239\n",
      " 0.8908706  0.8527037  0.98483247 0.8597653  0.975729   0.90909356\n",
      " 0.8834906  0.9680386  1.0801136  0.88260907 0.82906467 1.0193173\n",
      " 0.83325917 0.779171   1.2474359  1.031764   0.8375668  0.88362044\n",
      " 1.0682031  1.0746963  1.1129119  0.91758657 0.8526179  0.90965945\n",
      " 1.0115486  0.91165257 0.961937   1.05673    1.0205795  0.9003637\n",
      " 1.0985487  0.9863505  1.1639677  1.0728651  0.93147224 0.89087284\n",
      " 1.1422673  0.8919008  0.93642706 0.88995284]\n",
      "  Param 1 wieight: [-0.03002214 -0.28177932 -0.23691471 -0.34465984 -0.10817254 -0.12544857\n",
      " -0.28369853 -0.07345855 -0.24206889 -0.34350222 -0.23079787 -0.24748498\n",
      " -0.24192677 -0.13746469 -0.2002686  -0.09385337 -0.34413627 -0.35079062\n",
      " -0.16221866 -0.32246494 -0.39062494 -0.34111828 -0.29764846 -0.2793017\n",
      " -0.1395743  -0.23559266 -0.29709664 -0.3813013  -0.179387   -0.3487148\n",
      " -0.22699833 -0.24036719 -0.2759015  -0.24210389 -0.20926552 -0.35147506\n",
      " -0.24520096 -0.3528776  -0.38884336 -0.1519329  -0.38294822 -0.16692722\n",
      " -0.29603463 -0.14207086 -0.08781181 -0.34499806 -0.05352878 -0.16566423\n",
      " -0.41130286 -0.32926473 -0.3420007  -0.32038298 -0.07575609 -0.20943794\n",
      " -0.12697412 -0.29857564 -0.21825962 -0.10933381 -0.3606595  -0.11858508\n",
      " -0.16035934 -0.19679219 -0.12577558 -0.41396493]\n",
      "  Param 2 wieight: [-2.885164   -2.2606525  -1.4711862  -3.1266487  -1.7380495  -2.3827994\n",
      "  0.5968853  -0.51255834 -2.4460034  -2.1054113  -1.2460563  -2.2564235\n",
      " -1.4302539  -2.7752783  -1.3970625  -1.6886226  -1.1922001  -0.44498047\n",
      " -0.9472238  -1.7305566  -1.940773   -0.34195098 -1.2915267  -2.0983157\n",
      " -0.3145808   0.3529046  -1.7598219  -0.14465113 -1.4500341  -0.48381057\n",
      " -1.7921499  -2.4262335  -2.4394228  -0.65549964 -0.80350363 -1.9578385\n",
      " -0.20797178 -1.6225884  -2.7787852  -4.38054     1.3841348  -1.7763968\n",
      " -2.0993319  -1.8961678  -2.7069576  -1.9794534  -2.0107267  -0.39878452\n",
      " -2.424157   -1.310386   -2.0360146  -1.8216908  -2.352227   -1.329189\n",
      " -2.2172246  -1.3837053  -4.049726   -2.461916   -1.0412287  -1.1862073\n",
      " -3.1858785  -1.945855   -2.3749256  -0.47046262]\n",
      "  Param 3 wieight: [ 9.815613   6.864657   4.815346  10.216223   8.145485   9.161456\n",
      "  4.9918923  6.3639646  6.925212   7.1007113  6.780331   6.3178926\n",
      "  7.1158633 10.007438   7.6297936  8.3575735  8.664177   6.228969\n",
      "  7.454233   5.550485   7.0086117  6.873146   6.6858115  8.531015\n",
      "  6.3990955  4.796747   8.319559   6.342741   5.0600934  5.0981016\n",
      "  7.4168534  8.62515    6.7874265  4.7315483  6.0752535  6.656206\n",
      "  5.1422772  5.5155215 11.139704  12.54456    4.4185715  4.789983\n",
      "  5.946269   8.330619  11.011441   5.6991925  8.233691   6.7530847\n",
      "  7.9649844  6.3429284  6.894373  10.201545   9.169308   6.8336415\n",
      "  8.875392   5.4047823 12.859252   9.205219   5.1378117  5.1948113\n",
      " 11.950549   6.191918   8.415512   5.6094537]\n",
      "Layer 10: re_lu_2 (No weights)\n",
      "Layer 11: conv2d_3\n",
      "  Param 0 wieight: [[[[ 1.25266761e-01 -1.85423791e-01 -8.08826163e-02 ...  1.54389925e-02\n",
      "    -9.76935849e-02 -6.65393770e-02]\n",
      "   [ 1.57476254e-02 -1.16522402e-01  1.32973149e-01 ... -6.62513450e-02\n",
      "    -2.63128113e-02 -2.83152819e-01]\n",
      "   [ 1.53417485e-02  1.62658662e-01  9.87386853e-02 ... -6.64582923e-02\n",
      "    -6.68255314e-02  1.73121635e-02]\n",
      "   ...\n",
      "   [-1.08027123e-01  8.05875137e-02 -9.07270759e-02 ...  3.44853029e-02\n",
      "    -4.51934151e-02 -1.29483551e-01]\n",
      "   [ 4.50694747e-03  9.93265137e-02  3.77741340e-03 ...  5.90911396e-02\n",
      "     1.75997391e-01 -6.83407560e-02]\n",
      "   [-8.82631391e-02  9.99408122e-03  4.20794934e-02 ...  1.24249578e-01\n",
      "     8.55950341e-02 -1.67913213e-01]]\n",
      "\n",
      "  [[ 7.35798031e-02 -1.88797086e-01 -7.40794912e-02 ... -3.05428598e-02\n",
      "    -1.93425521e-01 -1.01375081e-01]\n",
      "   [-2.00264692e-01 -3.94342613e-04  2.33930707e-01 ...  6.40243068e-02\n",
      "     2.40751375e-02 -1.95836931e-01]\n",
      "   [-1.06915571e-02  5.77889495e-02  1.55025229e-01 ... -1.69664726e-01\n",
      "    -5.30692302e-02  7.18039647e-02]\n",
      "   ...\n",
      "   [-7.47186616e-02  1.68092772e-01  7.38508403e-02 ... -6.97532222e-02\n",
      "    -1.28272653e-01 -1.48930147e-01]\n",
      "   [-4.18907516e-02 -9.11532417e-02 -9.51804146e-02 ...  3.27362027e-03\n",
      "     8.42379704e-02 -2.91542616e-02]\n",
      "   [ 8.51824209e-02  1.45143852e-01  3.64720188e-02 ... -3.38182575e-03\n",
      "    -1.01640031e-01  8.09762776e-02]]\n",
      "\n",
      "  [[ 6.69309050e-02 -2.05511853e-01  1.63251758e-02 ...  3.14375982e-02\n",
      "    -5.20542525e-02 -1.16191618e-01]\n",
      "   [-2.66004503e-01 -2.76484340e-03  1.93523586e-01 ...  8.66388232e-02\n",
      "    -9.75540206e-02 -8.00384432e-02]\n",
      "   [-1.01732746e-01  1.08749971e-01  9.35389251e-02 ... -1.78934425e-01\n",
      "     1.10293478e-02  1.41525894e-01]\n",
      "   ...\n",
      "   [-8.08021277e-02  8.49904269e-02  6.24509921e-05 ... -5.73375113e-02\n",
      "     6.30910546e-02  1.15600772e-01]\n",
      "   [-6.74021542e-02 -9.62438881e-02  4.19422314e-02 ...  6.39725924e-02\n",
      "     8.31557661e-02 -5.79783022e-02]\n",
      "   [ 1.75537482e-01  1.02774166e-01  1.30130082e-01 ...  5.00897020e-02\n",
      "    -1.51167050e-01  5.82554005e-02]]]\n",
      "\n",
      "\n",
      " [[[ 2.16129333e-01  9.45309326e-02  1.83297750e-02 ... -3.49303968e-02\n",
      "    -2.96318084e-01 -2.32970025e-02]\n",
      "   [ 1.68744385e-01 -1.19062059e-01  5.96264377e-02 ... -7.09425285e-02\n",
      "    -1.83695722e-02 -1.10216744e-01]\n",
      "   [ 1.26916736e-01  8.42101276e-02  7.43658617e-02 ...  6.52953610e-02\n",
      "    -2.07220465e-01 -9.26794186e-02]\n",
      "   ...\n",
      "   [-1.21711947e-01  5.60488775e-02 -1.17300555e-01 ... -5.72468489e-02\n",
      "    -1.86419971e-02  3.23201828e-02]\n",
      "   [-7.61913583e-02  7.74761662e-02 -2.21093893e-01 ... -2.61882562e-02\n",
      "    -3.18777487e-02  8.73598084e-02]\n",
      "   [-2.45768771e-01 -7.52299745e-03  1.28021330e-01 ... -1.06017619e-01\n",
      "     1.52556688e-01 -1.28527254e-01]]\n",
      "\n",
      "  [[ 9.31872651e-02  8.33825693e-02 -1.15099281e-01 ...  6.64118305e-02\n",
      "    -2.15017080e-01 -4.93542552e-02]\n",
      "   [ 7.50843585e-02  1.35449888e-02  2.34804556e-01 ...  4.69464213e-02\n",
      "     1.47677273e-01  3.48139964e-02]\n",
      "   [ 4.35824022e-02 -9.70567949e-03  8.95937830e-02 ... -6.11742698e-02\n",
      "    -2.16773391e-01  9.12866518e-02]\n",
      "   ...\n",
      "   [-5.56731038e-02 -7.70348962e-03  3.48027758e-02 ... -7.24683926e-02\n",
      "    -7.41902813e-02 -1.38218375e-02]\n",
      "   [-2.08068967e-01 -1.04985693e-02 -2.78716058e-01 ... -5.45399785e-02\n",
      "     2.52524056e-02  3.70275341e-02]\n",
      "   [-1.28578156e-01  4.21801917e-02 -1.77530069e-02 ... -5.44579178e-02\n",
      "    -5.60165681e-02  1.38207868e-01]]\n",
      "\n",
      "  [[ 1.66871607e-01 -5.41087054e-02 -6.32585883e-02 ...  8.29681084e-02\n",
      "     1.12041878e-02 -6.38507828e-02]\n",
      "   [-1.37631372e-01 -3.46206762e-02  2.66161501e-01 ... -1.16857246e-01\n",
      "     9.14524198e-02 -1.08699068e-01]\n",
      "   [ 5.16656414e-02 -3.86785865e-02  2.02108040e-01 ...  1.42440731e-02\n",
      "    -2.38878861e-01  1.98451027e-01]\n",
      "   ...\n",
      "   [-1.40349101e-02 -9.70305651e-02 -1.32183179e-01 ...  4.16622609e-02\n",
      "     4.11093868e-02  1.30589321e-01]\n",
      "   [-1.26115203e-01 -2.96923250e-01 -2.56970882e-01 ... -5.91760911e-02\n",
      "     1.34611979e-01 -9.62947085e-02]\n",
      "   [ 1.12010762e-01  1.06994651e-01  3.16173173e-02 ...  8.93209279e-02\n",
      "    -6.34505153e-02 -1.52824735e-02]]]\n",
      "\n",
      "\n",
      " [[[ 1.56108677e-01  1.64710939e-01 -3.56723741e-02 ... -2.18891382e-01\n",
      "    -8.07524379e-03 -5.76845706e-02]\n",
      "   [ 1.74792796e-01  1.35951145e-02 -1.03404038e-02 ... -5.35289794e-02\n",
      "     8.74715298e-03 -2.03509461e-02]\n",
      "   [-6.22421019e-02  1.95977893e-02  7.54685476e-02 ...  1.53591901e-01\n",
      "    -1.33772597e-01 -3.79524156e-02]\n",
      "   ...\n",
      "   [-2.39477865e-02  3.47064175e-02 -4.02703360e-02 ...  2.53564902e-02\n",
      "    -5.92067055e-02 -1.11295730e-01]\n",
      "   [-1.17590755e-01  6.16576672e-02  4.19277474e-02 ...  1.71552345e-01\n",
      "    -5.52722141e-02  1.03297018e-01]\n",
      "   [-1.54523864e-01 -4.69173118e-02 -1.09622907e-03 ... -8.54119062e-02\n",
      "     3.90252061e-02 -1.37376919e-01]]\n",
      "\n",
      "  [[ 6.56636075e-07  1.05206415e-01 -1.15351722e-01 ... -2.65278757e-01\n",
      "     8.46530944e-02 -5.72262593e-02]\n",
      "   [ 1.47672832e-01  1.58852581e-02  1.82776585e-01 ...  2.98006199e-02\n",
      "     9.22189578e-02  5.87555729e-02]\n",
      "   [-1.38259875e-02  5.73616996e-02  1.71362117e-01 ...  5.61974235e-02\n",
      "    -2.27844685e-01  5.04687913e-02]\n",
      "   ...\n",
      "   [-1.21928610e-01 -3.42724994e-02 -1.67841520e-02 ... -5.01350500e-02\n",
      "    -9.10566896e-02 -2.79511482e-01]\n",
      "   [-1.93804607e-01 -1.09308489e-01 -1.53905854e-01 ...  1.19446293e-02\n",
      "     9.71302539e-02  5.10703176e-02]\n",
      "   [-7.67608583e-02  1.46757960e-01  5.61828278e-02 ... -1.61119383e-02\n",
      "    -6.94217533e-02  2.89916527e-02]]\n",
      "\n",
      "  [[ 8.43770709e-03 -5.92744909e-02 -1.86585486e-01 ... -2.18037754e-01\n",
      "     1.74098283e-01 -1.06277362e-01]\n",
      "   [-3.71820554e-02  1.80007741e-02  1.57498419e-01 ... -9.99666080e-02\n",
      "     1.17290104e-02  1.70678906e-02]\n",
      "   [-1.17687777e-01 -4.36049700e-02  1.89841747e-01 ...  4.62530702e-02\n",
      "    -2.29519308e-01  1.11217253e-01]\n",
      "   ...\n",
      "   [-5.75091504e-02 -1.36528119e-01 -1.48932680e-01 ... -2.95084026e-02\n",
      "    -2.13480622e-01 -2.00848788e-01]\n",
      "   [ 8.47946852e-03 -1.99110776e-01 -5.51396646e-02 ...  1.01342067e-01\n",
      "     7.66622275e-02 -1.16361968e-01]\n",
      "   [ 2.99971607e-02  8.04916141e-04 -4.32752408e-02 ... -5.86042404e-02\n",
      "    -1.31219804e-01  2.97294720e-03]]]]\n",
      "  Param 1 wieight: [-3.1708519e-04 -2.0169173e-03 -1.7094809e-03 -1.4540970e-03\n",
      " -3.1765059e-04 -9.2500384e-04 -2.1194178e-03  3.1884908e-04\n",
      " -9.0262340e-04  1.7500779e-03 -1.7517140e-04  1.3471199e-03\n",
      "  2.3027972e-04  7.3653500e-04  2.5395595e-03 -9.0669736e-04\n",
      " -2.5096082e-04  2.1957986e-03 -1.5106643e-04  5.4771840e-03\n",
      " -2.2238906e-05  3.2397889e-04 -1.3132865e-03  2.2560989e-03\n",
      "  2.2388724e-04 -2.1266136e-03  7.7038968e-04  2.7688692e-04\n",
      " -1.5776699e-03 -1.6913179e-04 -3.8197152e-03  1.9241122e-03\n",
      " -1.7585140e-03  1.7078490e-03  9.4799348e-04 -2.8727911e-03\n",
      "  1.9125591e-03  2.7004038e-03 -2.7563667e-03 -1.4344318e-03\n",
      "  5.0840527e-04 -1.1865787e-03  2.4746655e-04 -4.8069182e-04\n",
      " -1.6696252e-03  5.9740315e-04  2.2658501e-03 -1.5042599e-03\n",
      "  6.5403961e-04 -7.3701004e-04  2.7112143e-05  3.4863914e-03\n",
      "  1.7723585e-04  2.1642826e-03  8.6150394e-04 -6.2003976e-04\n",
      " -3.4529248e-03 -2.6828127e-03  1.1095130e-03  1.4656370e-03\n",
      " -6.9348083e-04  9.3760777e-05  3.8323514e-03  1.3649553e-03]\n",
      "Layer 12: batch_normalization_3\n",
      "  Param 0 wieight: [0.9258652  0.85870934 0.9234649  0.91198564 0.89238995 0.8946041\n",
      " 0.9135767  1.0158057  0.8494884  0.876816   0.8363679  0.8787497\n",
      " 0.8740879  0.87685364 0.9048085  0.8650996  0.8079276  0.9537285\n",
      " 0.9943992  0.9172979  0.8673455  0.85852    0.84763646 0.917701\n",
      " 0.94044465 0.8920069  0.8886351  0.8006485  0.93071085 0.92033017\n",
      " 0.9691517  0.86467284 0.91841125 0.9344973  0.8669326  0.8930748\n",
      " 0.95725495 0.8735705  0.9260044  0.8659952  0.83424705 0.8934391\n",
      " 0.8761991  0.93869025 0.9316809  0.9190179  0.8431553  0.8797489\n",
      " 0.85620064 0.8403902  0.92515695 0.9161522  0.84500766 0.865085\n",
      " 0.95196027 0.9052414  0.8962951  0.89032906 0.92564803 0.8444105\n",
      " 0.8821887  0.87214184 0.91274184 0.9275014 ]\n",
      "  Param 1 wieight: [-0.63539934 -0.5829195  -0.4119504  -0.5632741  -0.6236624  -0.5462463\n",
      " -0.5942585  -0.78307045 -0.69888824 -0.6304055  -0.40597638 -0.7615837\n",
      " -0.5611531  -0.59012175 -0.54540014 -0.83149046 -0.57692575 -0.66035575\n",
      " -0.69990635 -0.52948445 -0.69243234 -0.5044726  -0.4804691  -0.54525536\n",
      " -0.738297   -0.526037   -0.52830124 -0.61006314 -0.5394766  -0.5927913\n",
      " -0.6549349  -0.47515926 -0.5084441  -0.8178428  -0.4816879  -0.61634696\n",
      " -0.5085445  -0.56443536 -0.643442   -0.5133574  -0.5774425  -0.92476517\n",
      " -0.52102256 -0.6326507  -0.46232373 -0.60995066 -0.61058223 -0.36293638\n",
      " -0.53046525 -0.5095444  -0.53291315 -0.6757613  -0.51516217 -0.5782691\n",
      " -0.48955196 -0.6219233  -0.6811946  -0.43254313 -0.71805847 -0.41110998\n",
      " -0.756274   -0.678482   -0.6483052  -0.6035598 ]\n",
      "  Param 2 wieight: [-0.20682484 -0.9711039  -2.5785372  -4.6134443  -4.5442047   1.0276412\n",
      " -1.2349411  -2.0592911  -4.3522534  -1.999802    0.0620781  -1.8413895\n",
      " -1.243486   -2.5681212  -3.848124   -2.7761607  -0.35109633 -2.5243866\n",
      " -1.5497464  -0.7949445  -3.7473776  -2.8539927  -2.5252364  -2.121392\n",
      " -1.968332   -1.0300323  -1.0041595  -3.0143144  -1.7376912  -1.1598594\n",
      " -2.4335933   3.0738697  -2.026708   -1.6819001  -3.9238114  -0.356867\n",
      "  2.971765   -3.9684289  -2.1690738  -4.563837   -3.7705953  -3.1747723\n",
      " -2.7897112  -0.41659462  0.3368829  -0.68391246 -4.5690036  -1.7162398\n",
      " -0.54004085 -2.4356883  -5.0991693  -2.7011988  -2.0172806  -1.800969\n",
      " -4.0160527  -1.2056261  -5.117254    0.64645153 -2.9410055   0.01767628\n",
      " -1.0939939  -2.3592887  -1.790098   -2.3385298 ]\n",
      "  Param 3 wieight: [6.435474  3.5464184 6.548894  6.5201387 7.7959437 5.5976896 4.7251835\n",
      " 5.699619  6.4503307 5.535412  3.5801413 3.8001487 5.6655316 4.852867\n",
      " 3.8558202 4.8288364 4.2983513 4.5835633 6.089679  4.5153923 5.556249\n",
      " 4.12717   4.631441  5.33737   4.190146  5.4513397 5.4966207 7.0617385\n",
      " 5.204625  4.7249675 5.4416995 5.4555097 6.1506796 3.520354  6.5610967\n",
      " 5.9088383 6.7466125 5.3268194 4.575285  5.400427  5.7453556 4.012218\n",
      " 5.6323795 4.589799  6.718352  4.908019  5.194693  4.795659  5.2980533\n",
      " 5.572949  7.1875014 4.3574443 4.7228484 4.7537117 5.9430785 4.3835735\n",
      " 5.371497  5.7116203 5.516736  5.28077   4.756169  4.7899933 4.47118\n",
      " 5.2254705]\n",
      "Layer 13: re_lu_3 (No weights)\n",
      "Layer 14: max_pooling2d_1 (No weights)\n",
      "Layer 15: dropout_1 (No weights)\n",
      "Layer 16: conv2d_4\n",
      "  Param 0 wieight: [[[[-1.82798002e-02 -4.19877190e-03 -2.20803097e-01 ...  1.17530055e-01\n",
      "     2.50753164e-02  1.81192994e-01]\n",
      "   [-4.55478281e-02  1.92126278e-02 -5.12209833e-02 ...  4.34755757e-02\n",
      "     1.77606538e-01  4.62421663e-02]\n",
      "   [-1.78098530e-01  1.54529929e-01 -3.52382660e-02 ...  1.94400623e-01\n",
      "     1.63289174e-01  1.54675841e-01]\n",
      "   ...\n",
      "   [ 1.75786316e-01 -4.90739644e-02  1.08028343e-03 ...  7.50355721e-02\n",
      "    -1.78735986e-01  1.67728648e-01]\n",
      "   [-3.33382152e-02 -1.39773607e-01  6.91070631e-02 ...  1.06540866e-01\n",
      "     2.41223171e-01  1.73626337e-02]\n",
      "   [ 3.66038568e-02  2.06771418e-01  3.20975296e-02 ... -3.14820230e-01\n",
      "     7.55433142e-02  1.60856899e-02]]\n",
      "\n",
      "  [[-2.09934607e-01 -3.09905410e-02 -3.55073288e-02 ...  1.42271087e-01\n",
      "    -1.86734516e-02  2.17614397e-01]\n",
      "   [-1.36779085e-01  4.62084152e-02 -5.81458360e-02 ...  5.80784976e-02\n",
      "     1.21663742e-01 -5.05144037e-02]\n",
      "   [ 2.06231102e-02  1.06737062e-01 -7.62337893e-02 ...  7.98555166e-02\n",
      "     2.13268593e-01  6.12810366e-02]\n",
      "   ...\n",
      "   [ 7.01183751e-02  1.33594647e-02 -5.76790087e-02 ...  8.68325606e-02\n",
      "    -1.16677351e-01  7.39579797e-02]\n",
      "   [ 9.23633724e-02 -1.86642230e-01  3.51920724e-02 ...  4.09246329e-03\n",
      "     1.37093470e-01  3.79520245e-02]\n",
      "   [-1.14849396e-01  7.14554489e-02  9.73798241e-03 ... -7.28817983e-03\n",
      "     5.80288842e-03  1.26267867e-02]]\n",
      "\n",
      "  [[-2.96940833e-01  4.54107039e-02 -8.62864032e-02 ...  4.68181446e-02\n",
      "     2.82083191e-02  6.22920096e-02]\n",
      "   [-1.78411528e-01 -8.85198340e-02  1.13275521e-01 ... -5.25174960e-02\n",
      "    -6.80636689e-02  9.54276994e-02]\n",
      "   [-1.24972455e-01  9.05165821e-02 -1.07042372e-01 ... -4.87226173e-02\n",
      "     1.38059765e-01  1.97489530e-01]\n",
      "   ...\n",
      "   [-1.37535721e-01  1.06881067e-01 -7.24488050e-02 ...  1.38420733e-02\n",
      "    -1.33334100e-01  1.25475407e-01]\n",
      "   [-4.50805947e-02 -1.73490658e-01 -1.10548651e-02 ... -5.87750301e-02\n",
      "     6.29218742e-02  1.47279100e-02]\n",
      "   [-2.00334147e-01  2.76030805e-02  7.95316771e-02 ... -2.43930984e-02\n",
      "    -1.33828342e-01 -9.94952396e-03]]]\n",
      "\n",
      "\n",
      " [[[ 2.07475156e-01 -8.79746825e-02 -2.29500532e-01 ...  1.12293467e-01\n",
      "     1.70518234e-01  1.13606825e-02]\n",
      "   [-1.23379659e-03 -1.19154528e-01 -4.94002402e-02 ... -1.58965573e-01\n",
      "     1.51709095e-01 -7.00742751e-02]\n",
      "   [ 3.54097486e-02  1.58857331e-01 -1.43179625e-01 ... -2.46475060e-02\n",
      "     1.16889983e-01  9.14088860e-02]\n",
      "   ...\n",
      "   [ 7.78424665e-02  3.70140597e-02 -7.84340799e-02 ... -1.48879424e-01\n",
      "     2.11518500e-02 -7.63197467e-02]\n",
      "   [-9.94266272e-02 -2.69173503e-01 -2.01890558e-01 ...  7.67435580e-02\n",
      "     9.32559371e-02 -6.39626384e-02]\n",
      "   [ 1.58813283e-01  1.68421388e-01 -1.32455572e-01 ... -2.93956790e-02\n",
      "    -1.11610495e-01  1.16369180e-01]]\n",
      "\n",
      "  [[-3.82064395e-02  2.00908929e-02 -5.90312295e-02 ...  1.21083140e-01\n",
      "     1.08107135e-01  7.25960061e-02]\n",
      "   [ 2.60122363e-02 -1.02765389e-01 -8.05560574e-02 ...  1.39564380e-01\n",
      "    -8.74702185e-02 -7.08670169e-02]\n",
      "   [ 4.68323529e-02  7.82715455e-02 -1.43927738e-01 ...  6.14789017e-02\n",
      "     1.14350274e-01 -4.94387327e-03]\n",
      "   ...\n",
      "   [ 1.75001130e-01 -4.73764427e-02  8.25829525e-03 ... -9.25443508e-03\n",
      "     1.00297518e-01  6.81011900e-02]\n",
      "   [ 2.15712339e-02 -1.69111744e-01 -2.60307670e-01 ...  1.05676323e-01\n",
      "     8.44581053e-02 -1.06954299e-01]\n",
      "   [-6.23046234e-02  1.10502318e-01 -1.27167299e-01 ...  7.37474263e-02\n",
      "    -1.52255848e-01  9.70551968e-02]]\n",
      "\n",
      "  [[-6.08099848e-02 -1.01449543e-04  5.28784692e-02 ...  3.68859991e-02\n",
      "     1.63499743e-01  5.20893000e-02]\n",
      "   [-6.49270713e-02 -1.10097818e-01  1.32204583e-02 ...  1.22053921e-01\n",
      "     9.09763388e-03  1.57606617e-01]\n",
      "   [-2.82533318e-02  8.49577710e-02 -1.30437881e-01 ... -2.67878044e-02\n",
      "     9.10676420e-02  1.78018123e-01]\n",
      "   ...\n",
      "   [-7.20349401e-02  9.21664536e-02 -2.02631089e-03 ... -1.91437125e-01\n",
      "    -3.83127481e-02  3.37613188e-02]\n",
      "   [-5.41493669e-02 -6.49221838e-02 -1.28785089e-01 ...  3.95170264e-02\n",
      "    -7.78578408e-03 -9.46786180e-02]\n",
      "   [-8.12844187e-02  8.98659900e-02 -1.33664206e-01 ...  8.73799920e-02\n",
      "    -1.51964560e-01 -9.92316157e-02]]]\n",
      "\n",
      "\n",
      " [[[ 3.13656241e-01  3.71533036e-02 -1.38478979e-01 ... -7.79724941e-02\n",
      "     1.13731861e-01 -6.89469650e-02]\n",
      "   [-9.48920206e-04 -5.05969971e-02  1.64782219e-02 ... -2.36113518e-02\n",
      "    -3.70216891e-02  5.73161393e-02]\n",
      "   [ 1.27208248e-01  4.28826362e-02  5.82062565e-02 ... -3.10550690e-01\n",
      "    -4.63108532e-03 -2.05927178e-01]\n",
      "   ...\n",
      "   [ 7.58805647e-02  5.43375574e-02 -1.18450657e-01 ... -3.82563889e-01\n",
      "    -3.60191315e-02 -7.05403788e-03]\n",
      "   [-6.51791915e-02 -1.97258443e-01 -2.24242717e-01 ... -1.94314960e-03\n",
      "    -3.93579304e-02 -1.89619780e-01]\n",
      "   [ 3.66052277e-02  3.75083126e-02 -1.43550197e-03 ...  1.77876458e-01\n",
      "    -2.02799678e-01  2.42217526e-01]]\n",
      "\n",
      "  [[ 1.32808074e-01 -8.03270265e-02 -1.27987057e-01 ...  3.26944664e-02\n",
      "     6.63375631e-02 -4.31446126e-03]\n",
      "   [ 6.27056137e-02 -1.27517596e-01 -1.44381151e-01 ...  1.69198141e-01\n",
      "     8.46616402e-02  1.57111317e-01]\n",
      "   [-1.19883038e-01 -1.46174533e-02 -2.83352714e-02 ... -1.27912834e-01\n",
      "    -5.54344058e-02 -1.11813754e-01]\n",
      "   ...\n",
      "   [ 9.13992152e-02  1.33046051e-05 -2.18483191e-02 ... -1.44255266e-01\n",
      "    -1.54492840e-01 -1.68143570e-01]\n",
      "   [-4.79098447e-02 -7.45267943e-02 -2.10488856e-01 ...  1.11133404e-01\n",
      "     1.87138095e-02 -2.83248782e-01]\n",
      "   [ 5.03803864e-02  3.03385593e-02 -1.13558218e-01 ...  1.88955188e-01\n",
      "    -6.94741448e-03  1.63137987e-01]]\n",
      "\n",
      "  [[ 1.22315111e-02 -1.47705991e-02  4.00373107e-03 ...  2.44852994e-02\n",
      "    -1.21996030e-01 -5.36326692e-03]\n",
      "   [ 5.00634760e-02 -8.29087719e-02 -1.11390911e-01 ...  1.47818223e-01\n",
      "     1.36883810e-01  2.23233461e-01]\n",
      "   [-1.24593794e-01 -4.05712873e-02  5.43244835e-03 ... -1.28839329e-01\n",
      "    -2.03745544e-01  1.40890047e-01]\n",
      "   ...\n",
      "   [-3.27205993e-02 -7.25644454e-02  3.26372497e-02 ... -2.06428885e-01\n",
      "    -2.88191825e-01 -9.25360471e-02]\n",
      "   [ 1.34625528e-02  3.71970162e-02 -3.30389321e-01 ...  5.78542016e-02\n",
      "     2.18575876e-02 -1.12362079e-01]\n",
      "   [ 5.29957078e-02  3.57690714e-02 -1.85495287e-01 ...  7.21979216e-02\n",
      "     7.29100183e-02  1.37925148e-01]]]]\n",
      "  Param 1 wieight: [ 3.5713756e-04  1.1318629e-04  2.8759934e-04 -1.6180909e-04\n",
      " -4.1083793e-05 -1.2988563e-03  2.3191501e-03 -7.5503474e-04\n",
      " -2.4332864e-04  2.4470239e-04  1.0425771e-03  3.9735347e-05\n",
      " -8.4093719e-04 -8.8950526e-04  1.0088375e-04 -5.5955403e-04\n",
      " -6.2923844e-04  8.7862072e-04  5.2432291e-04  6.2032824e-04\n",
      "  4.3912831e-04 -3.8968126e-04 -1.5275566e-04 -3.0084906e-04\n",
      " -2.3503734e-04 -1.4870436e-04 -5.1378948e-04 -1.2059152e-03\n",
      "  4.2982146e-04 -4.7138339e-04 -3.7142445e-04  8.8749599e-04\n",
      " -4.5542765e-05 -6.0360954e-04 -2.2302310e-04 -2.2738164e-04\n",
      " -4.2260185e-04 -9.8333473e-04 -4.8185399e-04 -2.4107163e-05\n",
      " -2.3121497e-04  3.2270633e-05 -2.8506535e-04 -2.0768415e-04\n",
      "  1.6550844e-03  1.1138121e-04  4.3733272e-04  6.8417017e-04\n",
      " -5.8925616e-05 -1.1177713e-03  3.2633130e-04  3.5706648e-04\n",
      "  5.5105171e-05  3.4840868e-04  1.9374372e-04 -3.2470527e-04\n",
      " -4.3756567e-04 -3.5321456e-04  1.7360871e-04  3.1960139e-04\n",
      " -1.2587427e-04  8.1716804e-04  7.7497083e-05 -1.2656025e-04\n",
      " -2.7188685e-04 -3.4532950e-06  4.1151285e-04 -1.6734336e-04\n",
      " -3.1983084e-04  5.3046530e-05  3.2333404e-04 -3.6861707e-05\n",
      " -1.7916156e-03  3.7940740e-04 -3.5655117e-04  3.7392812e-05\n",
      " -6.2575197e-04  4.5536936e-04 -4.8221750e-04 -4.5950740e-04\n",
      " -1.1116593e-03  7.3119439e-04  8.7009952e-04 -6.5874396e-05\n",
      " -3.1413732e-04  1.7315544e-04  4.4794849e-04  9.5942372e-04\n",
      "  6.9554715e-04  1.1961475e-03 -7.0913089e-04 -6.3156569e-04\n",
      " -2.0230036e-04 -2.0878771e-04  1.4394992e-03 -6.2913750e-04\n",
      "  5.8068632e-04  5.6928082e-04 -1.0387809e-03  8.9074904e-04\n",
      " -2.5196638e-04 -1.0794683e-03 -4.2140088e-04 -7.0669048e-04\n",
      " -1.8182500e-04 -8.9351088e-04  3.2561721e-04 -9.1344402e-05\n",
      "  3.7790032e-05 -7.9524511e-04  1.1759542e-03  5.1561953e-04\n",
      "  6.0262770e-04  1.5140181e-04 -1.6651734e-03 -4.6904392e-05\n",
      " -2.4497468e-04 -5.5545528e-04  1.5207173e-03  1.5090003e-03\n",
      " -6.6115765e-04 -2.1715980e-04  1.0977526e-04 -2.9111581e-04\n",
      "  4.0406213e-04 -3.7111845e-04 -3.6204906e-04  1.8732996e-04]\n",
      "Layer 17: batch_normalization_4\n",
      "  Param 0 wieight: [0.7771944  0.80001897 1.0242505  0.9538423  1.0878676  0.9588888\n",
      " 0.90898615 1.0996485  0.93190813 0.95696074 0.87689084 1.093445\n",
      " 1.056047   0.9754325  1.0208182  1.0138322  1.102035   0.8771421\n",
      " 0.81941223 1.062055   0.90293634 0.8960605  0.9672726  0.94656885\n",
      " 0.80320656 0.84303427 0.9329064  0.95912445 0.9409523  0.960962\n",
      " 0.929303   0.8597658  0.91462827 0.97685724 0.98378754 0.8578564\n",
      " 0.91546863 0.9143936  0.88412917 1.04952    0.8385397  1.009295\n",
      " 0.96308714 1.0573496  0.92430234 1.0615295  0.9103902  0.9249266\n",
      " 0.8825073  1.0246711  0.9723417  0.87376505 0.83793855 0.95969796\n",
      " 0.95225525 1.0250245  0.9450461  1.08142    0.95850533 0.9221643\n",
      " 0.9792472  0.97194296 0.97675604 0.87349945 0.8990156  0.93864995\n",
      " 1.015647   0.84308594 0.900746   0.89848834 0.8750146  0.9509086\n",
      " 1.044097   0.8172757  0.89164543 0.98073405 1.0945239  1.0131611\n",
      " 1.1933448  0.8595382  1.0124407  1.0064926  0.997419   0.99099356\n",
      " 0.94505113 0.8793798  0.7641934  0.87527114 0.91038424 0.8816329\n",
      " 1.0344751  0.9948053  0.97452796 0.7354862  0.96207005 0.98706764\n",
      " 0.90835273 0.8950238  0.9004479  1.0094104  0.8108428  0.9979821\n",
      " 1.257671   1.0487453  0.92679983 1.0337931  0.98390806 0.94595575\n",
      " 0.95593387 0.97498214 0.9900706  0.83499414 1.1981235  0.9207995\n",
      " 0.95928985 0.9718126  0.8511662  0.9127368  0.9599422  0.9688732\n",
      " 0.8194544  0.8746447  1.1164666  0.8005916  0.8802618  0.8682209\n",
      " 0.8925392  0.9644979 ]\n",
      "  Param 1 wieight: [-0.5228016  -0.34796724 -0.31368685 -0.23414713 -0.32251662 -0.31562945\n",
      " -0.33796656 -0.29006243 -0.5536564  -0.39433578 -0.53615403 -0.49750164\n",
      " -0.2688135  -0.40049264 -0.38106024 -0.3254652  -0.3742271  -0.43002525\n",
      " -0.49755824 -0.2871507  -0.5274149  -0.44938308 -0.3933285  -0.354371\n",
      " -0.56708586 -0.6423861  -0.44261658 -0.39853013 -0.39913058 -0.42947033\n",
      " -0.56051046 -0.5660876  -0.41760874 -0.4305446  -0.19322178 -0.46498525\n",
      " -0.38507962 -0.42654058 -0.463052   -0.4041553  -0.59451085 -0.4283041\n",
      " -0.42363086 -0.60875523 -0.3396624  -0.3378367  -0.38688222 -0.31290346\n",
      " -0.46591753 -0.28424588 -0.45078856 -0.5280182  -0.37920642 -0.5862368\n",
      " -0.48199013 -0.33640796 -0.456439   -0.43501285 -0.20220667 -0.3731656\n",
      " -0.3894744  -0.6047417  -0.28861624 -0.4634539  -0.54593664 -0.4520043\n",
      " -0.33061084 -0.46036565 -0.34702405 -0.4078005  -0.28624034 -0.45808604\n",
      " -0.2679883  -0.41354907 -0.6099553  -0.4037454  -0.41945493 -0.41223443\n",
      " -0.39538538 -0.48150423 -0.340756   -0.48965567 -0.4079815  -0.3698664\n",
      " -0.37700462 -0.49712896 -0.32660595 -0.32143688 -0.5145904  -0.5014332\n",
      " -0.43583763 -0.40950608 -0.5035677  -0.51864564 -0.35768193 -0.4747516\n",
      " -0.59219766 -0.3181546  -0.2843834  -0.48893902 -0.49436435 -0.44546893\n",
      " -0.36352834 -0.49398798 -0.4091926  -0.4424732  -0.39309946 -0.42391843\n",
      " -0.52019054 -0.54422206 -0.29316524 -0.5666469  -0.5234728  -0.5346429\n",
      " -0.36931932 -0.5623958  -0.3020232  -0.60243005 -0.43382105 -0.3574271\n",
      " -0.4490692  -0.5513586  -0.26628798 -0.5209613  -0.46179226 -0.38648447\n",
      " -0.49572635 -0.45554057]\n",
      "  Param 2 wieight: [ 0.6460848   1.7661034  -4.804262   -2.5155213  -3.4718814  -1.3805419\n",
      " -0.32600844  0.23886964  0.81812835 -2.894123   -0.17185721 -0.98877764\n",
      " -2.4639616  -2.0547016  -4.9169846  -4.83348     0.08935494 -3.247591\n",
      "  0.2873637  -3.9988277  -0.54320437 -1.2319483  -3.6124048  -1.4322927\n",
      "  0.9723358   2.0924094  -3.3788166  -2.5032997  -2.5995936  -2.9540782\n",
      " -1.291262    0.44559556 -1.895219   -3.0991528  -4.8721952  -2.5662942\n",
      "  0.00850879 -0.03951266 -0.4899757  -3.2614508  -0.3573764  -1.2380539\n",
      " -1.9703531  -2.6784565  -0.74138105 -5.542938   -5.6873207   0.24814193\n",
      "  1.8544768  -1.6799406  -0.6632649   0.9140438  -2.4329066  -1.9834261\n",
      " -2.7436154  -2.5898843  -1.5474705  -1.7205392  -4.9124665  -3.08038\n",
      "  0.7989286  -2.0029612  -3.8972783   1.5569873  -2.2363486  -1.4728279\n",
      " -3.7102337  -0.97846216 -2.5524569  -2.741915   -1.9972903  -0.7295409\n",
      " -3.874479   -3.0183055  -2.0163355  -0.79678166 -1.8514662  -1.3101538\n",
      " -2.112489   -3.0654798  -2.1209385  -2.5959327  -1.9618073  -2.5757358\n",
      "  0.86607826  0.37714103 -2.5438213  -0.7322654  -2.2202103  -1.3301903\n",
      " -1.9666986  -2.2061288  -0.5042203  -1.2546104  -3.7190402  -0.46272427\n",
      " -2.3059409   0.8288991  -3.8857281  -1.5030029  -0.47076717 -4.3582363\n",
      " -2.7104158  -1.9499359  -1.3848466  -3.1755557   1.6560779  -0.15002403\n",
      "  0.20999219 -0.45942128 -4.165884   -0.29257253 -2.1864235  -3.0049438\n",
      " -2.3113482  -2.0408385   1.727435   -2.5406697  -2.478609   -1.2880684\n",
      "  0.48571247 -2.7088113  -1.7112586  -1.1141015  -4.235932   -2.3529794\n",
      "  0.69700176  0.8815218 ]\n",
      "  Param 3 wieight: [ 5.0266438  9.339726  12.692448   9.30754    7.2967253  6.5351286\n",
      "  8.44657    8.9297495  8.412175  11.023519   7.171624   7.363906\n",
      "  8.946845   7.604461  11.44831   12.332488   9.896494   8.794695\n",
      "  5.416148   9.488722   6.392417   7.777909  12.82044    7.814304\n",
      "  6.1703997  8.102943   9.6972065  9.50938    7.253458   9.377329\n",
      "  7.238323   7.729998   8.707769   7.8761964 11.00979    9.421254\n",
      "  8.166058   6.69502    8.076894   9.239237   6.848907  11.198429\n",
      "  8.66496    9.462917   7.2910705 14.31608   12.489329   7.244457\n",
      "  7.080647   8.530325   7.695705   6.056376   7.4387293  7.026203\n",
      "  7.0004773  7.721568   7.2850504  7.7140007 14.1848755  7.3578587\n",
      "  6.2723813  8.541045  10.36392    6.567672   6.4267516  7.610481\n",
      "  9.212268   8.689358   8.186939   8.719618   8.368386   8.406892\n",
      "  8.22439    8.381435   6.9770045  8.517578   8.572091  10.478581\n",
      "  7.266927   7.890284   8.846777   8.420044  10.727699  12.412018\n",
      "  7.1589694  6.2300096  7.6716256  8.539079   6.66475    7.7871623\n",
      "  8.664412   7.97281    9.083919   7.305259   9.854511   7.42882\n",
      "  7.1857934  9.16222    8.1842375  7.6168404  7.6656947  7.377656\n",
      " 10.813255   9.596578   7.9346614 10.615656   6.9125156  9.347392\n",
      " 10.091915   6.1879096  8.126609   6.0620255  8.340454   7.865501\n",
      "  8.603399   7.8087845  7.686691   6.7920337  8.107478   7.1646595\n",
      "  7.479485   6.2718067  8.60068    8.754806  11.631148   7.9180865\n",
      "  6.490665   9.117913 ]\n",
      "Layer 18: re_lu_4 (No weights)\n",
      "Layer 19: conv2d_5\n",
      "  Param 0 wieight: [[[[-2.32790217e-01 -3.77798155e-02  1.79216452e-02 ... -1.33136690e-01\n",
      "    -6.56312779e-02 -1.32080585e-01]\n",
      "   [-2.80899495e-01  4.94383043e-03  9.41582918e-02 ... -7.45761171e-02\n",
      "    -5.11154765e-03 -2.70398825e-01]\n",
      "   [ 9.19943117e-03  1.55267864e-01 -3.02076563e-02 ...  1.39594689e-01\n",
      "    -1.33784041e-01  1.00570098e-01]\n",
      "   ...\n",
      "   [ 2.26811573e-01  1.03746772e-01  6.18447214e-02 ... -2.37526536e-01\n",
      "    -6.71043471e-02  1.92409351e-01]\n",
      "   [-1.95738152e-01  1.19643413e-01 -9.32432637e-02 ... -1.16314538e-01\n",
      "     9.17343795e-02  2.87600793e-02]\n",
      "   [ 1.26489222e-01  2.50683725e-01 -1.06279925e-01 ...  1.32338092e-01\n",
      "    -2.95589149e-01  6.57138675e-02]]\n",
      "\n",
      "  [[-7.46424571e-02  9.17901099e-02  2.35511136e-04 ...  6.38112500e-02\n",
      "    -6.18411340e-02 -1.99560985e-01]\n",
      "   [-1.86468899e-01 -9.39253643e-02  8.28058198e-02 ... -1.32316053e-01\n",
      "     6.14137053e-02 -1.93034545e-01]\n",
      "   [ 1.23891351e-03  1.62510827e-01  2.24769162e-03 ...  5.18432818e-02\n",
      "    -1.34958342e-01  4.38844897e-02]\n",
      "   ...\n",
      "   [ 2.39045054e-01  3.31497937e-02 -6.20349795e-02 ... -1.16656087e-01\n",
      "    -6.41447231e-02  1.36571884e-01]\n",
      "   [-1.14301465e-01  1.39591515e-01 -1.11548699e-01 ... -7.22494647e-02\n",
      "     1.85649600e-02  1.91813335e-01]\n",
      "   [ 1.39884884e-02  1.04941532e-01 -1.47673726e-01 ...  7.23326802e-02\n",
      "    -7.05425963e-02  5.89407003e-03]]\n",
      "\n",
      "  [[ 1.27726436e-01  6.87498646e-03 -1.14268981e-01 ...  1.03867268e-02\n",
      "    -2.29242425e-02 -5.87056205e-02]\n",
      "   [-2.72503099e-03 -1.92041341e-02 -5.18740676e-02 ... -4.67819944e-02\n",
      "     1.83514208e-01 -1.34507313e-01]\n",
      "   [-5.77884316e-02  5.53728417e-02 -2.67735757e-02 ...  4.22821976e-02\n",
      "    -1.96221933e-01  9.86175239e-02]\n",
      "   ...\n",
      "   [ 1.36924550e-01  3.89639549e-02  6.60943463e-02 ... -1.77931815e-01\n",
      "    -8.85527357e-02  1.73108265e-01]\n",
      "   [-1.10398099e-01  2.27728009e-01 -1.47598833e-01 ...  9.55003779e-03\n",
      "     8.03161487e-02  1.04406759e-01]\n",
      "   [-1.34681955e-01  1.59328550e-01 -2.18998313e-01 ... -1.88203186e-01\n",
      "     5.93207916e-03 -6.81561008e-02]]]\n",
      "\n",
      "\n",
      " [[[-1.89156175e-01 -4.50091809e-02 -7.99377784e-02 ... -8.78828764e-02\n",
      "     2.88410559e-02 -3.26921754e-02]\n",
      "   [-5.52681386e-02 -7.40387768e-04  3.47451866e-02 ... -1.40361199e-02\n",
      "    -1.05579786e-01 -2.23120958e-01]\n",
      "   [ 1.17215859e-02  8.78277197e-02 -1.55756742e-01 ...  7.98309445e-02\n",
      "    -1.07166423e-02  8.70135576e-02]\n",
      "   ...\n",
      "   [ 1.46463156e-01  1.29057497e-01  2.10177246e-02 ... -7.94575810e-02\n",
      "     5.70971593e-02  1.65210709e-01]\n",
      "   [-1.20860778e-01  4.13370617e-02 -1.34740382e-01 ... -7.00200498e-02\n",
      "    -1.25107989e-01 -2.77635101e-02]\n",
      "   [-2.53629144e-02  5.58769181e-02 -8.52434263e-02 ...  6.38841614e-02\n",
      "    -2.44501606e-01  3.34988767e-03]]\n",
      "\n",
      "  [[-2.56009281e-01 -3.79819162e-02 -1.64766669e-01 ... -1.22618839e-01\n",
      "     1.77879669e-02 -3.60531034e-04]\n",
      "   [-1.27996296e-01 -3.01052388e-02  1.24381244e-01 ... -7.87810907e-02\n",
      "     2.35758722e-02 -1.28197655e-01]\n",
      "   [ 8.03460404e-02  3.83818336e-02 -9.66411904e-02 ...  1.04126565e-01\n",
      "     2.08261050e-02  1.14798412e-01]\n",
      "   ...\n",
      "   [ 7.36172274e-02  9.33037922e-02  4.22197916e-02 ... -5.47161475e-02\n",
      "    -6.73135519e-02  2.33426807e-03]\n",
      "   [-3.59237976e-02  9.62203890e-02 -1.54729158e-01 ... -1.00958019e-01\n",
      "    -8.24070796e-02  5.96361458e-02]\n",
      "   [ 1.05012599e-02 -1.45155489e-02 -1.30005449e-01 ... -3.90036404e-03\n",
      "    -1.24844462e-01  5.32767735e-02]]\n",
      "\n",
      "  [[ 1.60844810e-02 -5.24607003e-02 -2.00488910e-01 ... -1.05891399e-01\n",
      "    -1.20994933e-01  1.32692724e-01]\n",
      "   [-1.61227714e-02  6.72412280e-04 -5.95225357e-02 ... -5.90337366e-02\n",
      "     2.82960087e-02 -1.39725044e-01]\n",
      "   [-5.21134073e-03 -6.39607161e-02  7.33448798e-03 ...  3.64864841e-02\n",
      "    -1.28387049e-01  1.71035185e-01]\n",
      "   ...\n",
      "   [ 4.39093970e-02 -1.74426604e-02  7.45965391e-02 ... -1.96073651e-01\n",
      "    -1.12790158e-02  1.72829792e-01]\n",
      "   [-6.57307059e-02  1.28687084e-01 -2.12811291e-01 ...  2.91315652e-02\n",
      "     1.45252958e-01  2.64753066e-02]\n",
      "   [-9.66247618e-02  8.00883621e-02 -1.44012555e-01 ... -8.32843035e-02\n",
      "    -3.95331159e-02 -2.69330312e-02]]]\n",
      "\n",
      "\n",
      " [[[ 1.30721843e-02 -6.88003227e-02  9.06507894e-02 ...  1.82837620e-02\n",
      "    -1.20357700e-01  2.39066016e-02]\n",
      "   [-1.50439784e-01 -5.18978061e-03 -5.25332317e-02 ...  7.23451674e-02\n",
      "    -2.07174927e-01 -5.35555147e-02]\n",
      "   [ 2.45063752e-02  4.47845869e-02  5.06614521e-02 ... -6.63467720e-02\n",
      "     8.91074836e-02  8.00667256e-02]\n",
      "   ...\n",
      "   [-5.90751432e-02 -2.52681047e-01 -1.43813193e-01 ... -6.51507899e-02\n",
      "    -1.57737672e-01 -1.90002412e-01]\n",
      "   [-1.31888092e-01  6.59949034e-02 -9.72510651e-02 ... -1.93590131e-02\n",
      "    -1.47626430e-01  1.68772321e-02]\n",
      "   [-7.23982900e-02  1.31067529e-01  1.05663678e-02 ... -1.09948358e-02\n",
      "    -5.99188842e-02 -1.97476327e-01]]\n",
      "\n",
      "  [[ 5.74534945e-02 -1.53195873e-01 -6.33561313e-02 ... -9.25934762e-02\n",
      "    -1.21052951e-01 -7.58684007e-03]\n",
      "   [-3.13165900e-03 -3.32798213e-02 -4.01473008e-02 ... -4.88051437e-02\n",
      "    -1.23640381e-01  1.23388298e-01]\n",
      "   [ 5.16681485e-02 -1.13244476e-02 -2.81296652e-02 ... -6.19067950e-03\n",
      "     2.89818109e-03 -4.89238203e-02]\n",
      "   ...\n",
      "   [-1.96598675e-02 -3.16639960e-01  4.63231653e-02 ... -7.78160244e-02\n",
      "    -1.22695141e-01 -1.92168161e-01]\n",
      "   [-1.88278615e-01 -3.66113409e-02 -1.42964795e-01 ... -2.92170215e-02\n",
      "     9.89790447e-03  7.95502216e-02]\n",
      "   [-9.86551344e-02  4.65396903e-02  1.65156875e-04 ...  2.67355852e-02\n",
      "    -3.37445289e-01 -1.14014886e-01]]\n",
      "\n",
      "  [[-3.90109904e-02 -7.81555325e-02 -2.44020894e-01 ... -1.36987701e-01\n",
      "    -1.56873912e-01  2.19472453e-01]\n",
      "   [ 5.88901974e-02  5.48903756e-02 -1.52140453e-01 ...  9.30366945e-03\n",
      "    -2.79627200e-02  1.44036459e-02]\n",
      "   [ 7.58651597e-03 -8.47048238e-02  6.15519891e-03 ...  1.06736347e-02\n",
      "    -2.27820411e-01  7.57503211e-02]\n",
      "   ...\n",
      "   [-5.38989529e-02 -2.65371084e-01 -1.02491202e-02 ... -8.58251303e-02\n",
      "    -1.15709692e-01 -2.61960272e-02]\n",
      "   [-2.53708065e-01  3.95872146e-02 -8.30743536e-02 ... -8.89052674e-02\n",
      "     2.24390507e-01  4.51795384e-03]\n",
      "   [-8.96972716e-02  1.31550161e-02 -1.86232165e-01 ... -6.42480329e-02\n",
      "    -2.68525630e-01 -1.61185995e-01]]]]\n",
      "  Param 1 wieight: [-4.30265682e-05  2.36881111e-04 -2.07227713e-04 -3.69941044e-05\n",
      "  1.56108523e-04  5.16600965e-04 -3.44536675e-05 -7.43232900e-04\n",
      "  1.95844215e-04  4.36432427e-04  1.55305694e-04  6.26410329e-05\n",
      " -2.15448570e-04  3.69073561e-04  9.73846414e-04 -2.19287933e-04\n",
      " -7.87917466e-04  4.00154502e-04 -2.92196666e-04  1.04029321e-04\n",
      "  7.25205115e-04  2.93542107e-04 -2.53582948e-05 -3.29403585e-04\n",
      " -1.46223116e-03 -1.79331662e-04  4.54730645e-04  3.26373643e-04\n",
      "  2.06548750e-04 -4.16177529e-04 -1.45697792e-04 -4.35469468e-04\n",
      "  5.40542533e-04 -3.66168417e-04 -5.31828664e-05 -2.69137490e-05\n",
      "  6.66716951e-04  6.27959555e-04 -1.77707319e-04 -4.48704406e-04\n",
      "  2.93243647e-04  3.86753469e-04 -1.11059962e-04  8.41393718e-04\n",
      " -5.58658561e-04  5.15680586e-04  1.06205663e-03 -1.98743292e-04\n",
      " -5.95636840e-04 -3.21563886e-04 -2.77711551e-05 -6.40220416e-04\n",
      " -4.52009786e-04 -6.01335894e-04  4.59448114e-04  4.31053370e-04\n",
      "  9.29059388e-05 -2.18986868e-04  1.57607865e-04 -5.97711369e-05\n",
      " -3.91170965e-04  4.11231304e-04  4.71186650e-04  3.04705725e-04\n",
      " -3.68932262e-04 -1.98252892e-04  3.13819706e-04 -4.74379252e-04\n",
      " -2.42020527e-04  2.36921871e-04  5.94531244e-04  4.22280755e-05\n",
      " -2.85594317e-04 -3.93823168e-04  2.16862376e-04 -8.00172624e-04\n",
      " -2.76653445e-04  6.92693939e-05  3.77004289e-05 -5.94643789e-05\n",
      " -1.43085443e-03  7.91122147e-04  9.47041262e-05 -5.59691282e-04\n",
      "  1.02439262e-04  5.67342620e-04  3.91376088e-04 -5.56340616e-04\n",
      " -8.63256748e-04 -4.78899223e-04  3.22485284e-04 -1.04725346e-04\n",
      "  9.98728283e-05  4.01117199e-04  9.48241330e-04 -2.35832296e-04\n",
      " -1.39004056e-04 -1.00660705e-04  2.56888656e-04  1.01364322e-03\n",
      "  2.09274192e-04  5.78346488e-04 -8.43908754e-04  2.16477012e-04\n",
      "  1.46617313e-04 -8.26611009e-04  1.18568678e-04  2.74021935e-04\n",
      " -6.46368542e-04 -8.14127619e-04 -5.86094335e-04  1.74974353e-04\n",
      "  7.68025755e-04  8.50516662e-04 -5.49433287e-04 -2.77735351e-04\n",
      " -1.96856854e-05  9.03869339e-04 -1.86144767e-04  4.97827947e-04\n",
      "  1.12448307e-03 -4.24559490e-04 -3.07524111e-04 -2.78076419e-04\n",
      "  3.40708095e-04  3.15841608e-04  5.67988027e-04  1.47456434e-04]\n",
      "Layer 20: batch_normalization_5\n",
      "  Param 0 wieight: [0.52396744 0.47935507 0.49424857 0.557751   0.51789856 0.50510776\n",
      " 0.5574954  0.52631515 0.55765533 0.5630259  0.49868232 0.5693109\n",
      " 0.51167333 0.5283042  0.5210729  0.5378725  0.55714214 0.54511184\n",
      " 0.55269516 0.5164771  0.563169   0.5540002  0.5744326  0.4941085\n",
      " 0.5843374  0.5346383  0.5412296  0.5243764  0.5058115  0.5444583\n",
      " 0.54931754 0.52110535 0.5264839  0.49900547 0.47862762 0.5333568\n",
      " 0.5717976  0.53373176 0.52509457 0.50169444 0.52381146 0.51673394\n",
      " 0.5526511  0.5685137  0.52649087 0.5321946  0.5357712  0.56500596\n",
      " 0.49882168 0.48411143 0.53209597 0.5312263  0.5523864  0.49137047\n",
      " 0.56080204 0.53877217 0.5707025  0.5755681  0.47888172 0.52370054\n",
      " 0.6042249  0.5411036  0.5058531  0.5555717  0.5217715  0.54559076\n",
      " 0.57854295 0.5647128  0.5797745  0.52777976 0.56486493 0.53207886\n",
      " 0.5035306  0.52219373 0.56986254 0.5072072  0.5358177  0.60892004\n",
      " 0.497818   0.58951    0.5610201  0.53856224 0.5286609  0.5425092\n",
      " 0.54352266 0.4793165  0.53868276 0.50965023 0.50337124 0.53572994\n",
      " 0.51939595 0.53831506 0.5639637  0.56842595 0.57543635 0.54956603\n",
      " 0.53970706 0.5040118  0.5526603  0.57119334 0.5288722  0.54965264\n",
      " 0.530181   0.51101863 0.47993594 0.5213265  0.5126917  0.5055117\n",
      " 0.51971155 0.49864388 0.5035681  0.55357677 0.5801469  0.5526332\n",
      " 0.5321565  0.485849   0.5078382  0.47764975 0.54314286 0.59675175\n",
      " 0.50746775 0.565524   0.5045687  0.58086723 0.5703042  0.5223856\n",
      " 0.51158637 0.5318336 ]\n",
      "  Param 1 wieight: [-0.5267859  -0.5488825  -0.51672256 -0.560691   -0.62782514 -0.71652794\n",
      " -0.5880584  -0.561384   -0.6741524  -0.65135413 -0.5401121  -0.591946\n",
      " -0.597165   -0.64364594 -0.5900742  -0.5479593  -0.6348614  -0.59659\n",
      " -0.68397015 -0.61961293 -0.6177547  -0.64309984 -0.6539628  -0.5377896\n",
      " -0.6681776  -0.59202856 -0.56496835 -0.56556493 -0.62455535 -0.68296874\n",
      " -0.59071386 -0.64995855 -0.61641175 -0.5496343  -0.6183042  -0.6000147\n",
      " -0.64550954 -0.65550965 -0.55687827 -0.57937616 -0.67392206 -0.5804491\n",
      " -0.5743981  -0.6282238  -0.6399502  -0.58531004 -0.67139554 -0.5928908\n",
      " -0.5430296  -0.6600481  -0.6605328  -0.5749124  -0.6042682  -0.56744176\n",
      " -0.52492106 -0.5890685  -0.6838536  -0.6379825  -0.4883368  -0.651352\n",
      " -0.6664748  -0.62779474 -0.5201215  -0.68214107 -0.6371304  -0.67156214\n",
      " -0.6850478  -0.68858993 -0.71474737 -0.699408   -0.62238896 -0.5723971\n",
      " -0.6274393  -0.6076835  -0.66207254 -0.6618167  -0.57783836 -0.76444006\n",
      " -0.66722643 -0.6527039  -0.645784   -0.6280248  -0.57252645 -0.60005957\n",
      " -0.6384752  -0.49806988 -0.56948125 -0.62597185 -0.62664914 -0.7157808\n",
      " -0.5478829  -0.5736825  -0.6285359  -0.7137401  -0.66703737 -0.59274274\n",
      " -0.662453   -0.6201116  -0.5418729  -0.6917369  -0.6245912  -0.6204868\n",
      " -0.5645646  -0.42277905 -0.5853825  -0.57708466 -0.65641147 -0.6299592\n",
      " -0.59930396 -0.5490436  -0.5516567  -0.62221885 -0.7111607  -0.6021385\n",
      " -0.7209393  -0.5746324  -0.586557   -0.4446856  -0.59406066 -0.6194647\n",
      " -0.5542144  -0.6459183  -0.56124175 -0.6410392  -0.63532066 -0.61695695\n",
      " -0.61487025 -0.58894086]\n",
      "  Param 2 wieight: [-6.186294   -3.0124013  -3.3968756  -5.3023124  -5.499646   -4.6975408\n",
      " -5.3628364  -4.221325   -4.186044   -5.770526   -6.172301   -4.286895\n",
      " -3.6414587  -4.4374695  -5.500828   -3.9416714  -4.9996305  -3.7536802\n",
      " -6.490612   -5.379459   -4.027155   -3.6693764  -5.572666   -5.39365\n",
      " -6.3005753  -5.936424   -5.1525106  -5.3633323  -3.949796   -5.5976543\n",
      " -4.545619   -4.7889752  -6.030164   -5.3821745  -5.8595357  -4.5694323\n",
      " -5.209295   -3.3911746  -3.8482757  -5.3203526  -1.4543447  -5.2478833\n",
      " -3.7780094  -3.1666074  -5.711218   -3.630143   -2.6371846  -4.749407\n",
      " -6.090717   -0.39695498 -2.689651   -6.3198957  -5.7258096  -4.0110135\n",
      " -3.6949553  -4.7031546  -3.1396282  -5.0807347  -5.4050527  -2.9585204\n",
      " -4.4340434  -4.554305   -5.16926    -3.7182887  -4.2637596  -5.0241914\n",
      " -5.9483395  -4.4950266  -2.8714252  -0.9240215  -6.50423    -4.96818\n",
      " -5.908988   -5.4736376  -6.522979   -5.365237   -4.227088   -3.1613407\n",
      " -3.025394   -5.8821507  -4.3870363  -5.4221406  -5.9340653  -2.780769\n",
      " -3.5970893  -4.992172   -3.855547   -4.8540697  -3.8631792  -5.4005184\n",
      " -4.1059284  -2.1021574  -5.3928285  -4.763825   -4.308666   -4.1583557\n",
      " -4.877992   -5.0323668  -5.161742   -4.945747   -5.8252916  -4.736382\n",
      " -5.74566    -6.1485267  -2.0626707  -4.7794337  -1.3503947  -5.7895365\n",
      " -5.2179155  -6.002878   -6.087252   -4.2504034  -3.786532   -4.4007335\n",
      " -4.8170333  -3.994069   -2.2423205  -3.3450682  -5.658545   -7.154109\n",
      " -3.7573884  -3.7991326  -3.8593595  -5.623248   -3.6965718  -2.3584428\n",
      " -4.423682   -4.297745  ]\n",
      "  Param 3 wieight: [17.044664  13.322135  13.206844  14.182805  10.360953   7.3911343\n",
      " 11.226521  10.942618   7.9988523 13.203857  13.071365  18.503813\n",
      "  9.42908   11.06478   11.953732  13.467742  11.405204  11.824895\n",
      " 10.286637   8.456275  10.339517  10.747001  14.61527   12.836305\n",
      " 14.3747015 12.879496  14.487748  10.556972  10.898114  10.254904\n",
      "  7.797824   8.821874  10.046751  11.188705   8.663931  10.395224\n",
      " 11.999883  10.36621   11.477663  11.651691   9.757649  13.139442\n",
      " 12.24154   10.58103    8.740026  12.94406    8.333954  15.073383\n",
      " 12.243168   8.992676  10.506648  12.416349  15.219024  12.178133\n",
      " 12.303991  10.924191  10.6847315 11.744033  15.399718   9.607255\n",
      " 11.2129    10.054358  14.3126545  8.267256   9.975844  11.956336\n",
      " 10.205156   8.901381   9.352652  10.52695   12.820768  15.222641\n",
      "  7.7273846  8.000782  10.887272   8.944058  12.599787   9.453247\n",
      " 10.460617   9.641434  11.252257   7.842721  10.897842  10.03677\n",
      "  8.515227  11.944003  10.283497  10.76135   10.338186   7.378012\n",
      " 14.701908  13.030771  11.220867   9.036443  10.472818  11.176281\n",
      "  9.775673  10.372217  17.050152   9.166907  10.055942   9.661024\n",
      " 13.426146  22.249178  12.787103  13.097076  10.765299   9.178784\n",
      " 10.141287  13.795758  10.058155  14.3200655  9.429297  10.305638\n",
      "  7.5798945 11.027508   8.002023  12.2697315 14.599347  15.782634\n",
      " 13.896086  11.621483  12.532749   9.355892  10.923933   9.766159\n",
      " 11.325558   9.233701 ]\n",
      "Layer 21: re_lu_5 (No weights)\n",
      "Layer 22: max_pooling2d_2 (No weights)\n",
      "Layer 23: dropout_2 (No weights)\n",
      "Layer 24: flatten (No weights)\n",
      "Layer 25: dense\n",
      "  Param 0 wieight: [[ 0.021802    0.03612533 -0.01405126 ... -0.03257039 -0.06134871\n",
      "  -0.01956146]\n",
      " [ 0.0052167  -0.03954702 -0.07195938 ...  0.05230173 -0.02691746\n",
      "  -0.01146881]\n",
      " [-0.03140287 -0.03273322 -0.00938144 ...  0.03573802  0.02167168\n",
      "  -0.06487171]\n",
      " ...\n",
      " [ 0.04054177  0.01179342  0.01623096 ... -0.04385443  0.02662526\n",
      "  -0.03191039]\n",
      " [-0.0024702  -0.00072896  0.04216972 ... -0.01867491 -0.0661592\n",
      "   0.03354449]\n",
      " [-0.00537133 -0.01476471 -0.09492977 ... -0.06602383 -0.05873151\n",
      "   0.0731464 ]]\n",
      "  Param 1 wieight: [-2.14244109e-02 -6.74863979e-02 -2.35727821e-02  4.07368504e-02\n",
      "  8.87977332e-03 -2.70303320e-02  5.97427227e-02  9.77220759e-03\n",
      " -3.12332567e-02 -4.23717462e-02  5.72891496e-02 -6.21716827e-02\n",
      " -3.25013548e-02 -1.75281670e-02  1.07404679e-01 -3.22563313e-02\n",
      " -3.86365838e-02  4.15614359e-02 -3.99889722e-02  9.05025285e-03\n",
      " -8.84740707e-03  1.98069647e-01 -4.19140309e-02 -3.85748483e-02\n",
      "  2.95623974e-03  8.63134414e-02 -4.31390926e-02 -2.15228721e-02\n",
      "  1.60409268e-02 -7.00007975e-02 -4.80055213e-02 -4.40208875e-02\n",
      " -2.82448102e-02 -9.09378827e-02 -3.65263633e-02 -2.84964778e-02\n",
      " -8.91620107e-03 -5.19589595e-02 -4.08995748e-02 -4.94028218e-02\n",
      " -6.22261828e-03 -2.93004438e-02 -4.44640070e-02  9.46546867e-02\n",
      "  9.85288173e-02 -3.95576581e-02 -8.22563618e-02 -4.80108112e-02\n",
      "  8.73237029e-02 -5.51909879e-02  9.64640453e-02 -2.32871938e-02\n",
      "  9.53594521e-02  6.85896426e-02  4.08238247e-02  1.44248810e-02\n",
      " -5.72755747e-02 -7.20654009e-03 -6.77349344e-02 -5.12210838e-02\n",
      " -3.20459045e-02 -6.28091097e-02 -4.64258716e-02  4.25858535e-02\n",
      "  4.57409397e-02 -3.95749249e-02  1.10376596e-01  4.72866185e-02\n",
      " -2.36352663e-02 -1.51841044e-02 -4.74423692e-02 -3.12523693e-02\n",
      "  1.12560265e-01 -3.79275605e-02 -4.03986908e-02  9.55112204e-02\n",
      " -2.72055361e-02 -3.85254920e-02 -4.10950296e-02  6.60856999e-03\n",
      "  4.48158458e-02  3.98642756e-02 -4.10416462e-02  1.86132919e-02\n",
      "  3.47219012e-03  9.63491350e-02 -6.55620694e-02 -7.45625347e-02\n",
      "  6.86290786e-02 -3.39976922e-02 -3.46660498e-03 -5.10309637e-02\n",
      " -7.83676058e-02  2.00465973e-02  1.23182826e-01 -5.54222018e-02\n",
      " -8.68978631e-03 -3.68699767e-02  3.85723487e-02  4.10260893e-02\n",
      " -2.58088466e-02  1.20264487e-02  8.60201195e-03 -6.21783361e-02\n",
      "  4.13362011e-02  2.96009313e-02 -6.99711218e-02 -5.35424352e-02\n",
      " -1.52701400e-02  7.04885051e-02 -4.53109331e-02 -1.24941617e-01\n",
      "  1.38730526e-01 -3.50144468e-02 -4.48519625e-02 -6.52231043e-03\n",
      " -5.96940331e-02 -8.31679255e-02 -6.63764328e-02 -1.48933018e-02\n",
      "  7.90284853e-03  5.53948730e-02 -5.95112778e-02 -3.77950817e-02\n",
      " -4.56020534e-02  5.87112643e-02 -3.34498249e-02  4.74896375e-03\n",
      " -1.27916530e-01 -7.30775744e-02  7.16441683e-03 -4.29714955e-02\n",
      " -2.94889007e-02 -1.02448910e-01  3.65917757e-02  4.82657254e-02\n",
      " -6.90697283e-02 -5.53880706e-02 -5.53205498e-02  1.49905875e-01\n",
      " -3.96908969e-02  1.55723235e-02 -5.15911765e-02 -4.42096740e-02\n",
      " -4.15798239e-02  3.67691778e-02 -6.13730699e-02 -6.05475791e-02\n",
      " -2.35260744e-02 -2.46442072e-02 -4.72471006e-02 -2.82560177e-02\n",
      " -7.59538934e-02  1.54413497e-02 -3.95165980e-02  1.80599183e-01\n",
      "  1.95935685e-02 -1.28053188e-01  2.67778467e-02 -2.05097068e-02\n",
      "  1.31662190e-01  3.38649862e-02 -5.32542132e-02 -4.78697680e-02\n",
      " -1.07045751e-02 -3.12560275e-02  1.81757554e-01 -7.49089271e-02\n",
      " -6.62015006e-02  4.43021730e-02 -6.12520501e-02 -5.19301705e-02\n",
      " -7.48954043e-02 -5.74247167e-02  1.19442515e-01  2.67261509e-02\n",
      " -3.04647926e-02  1.02448717e-01  6.97299317e-02 -3.29748169e-02\n",
      "  3.90464626e-02  5.26099950e-02 -4.63364646e-02 -6.97889253e-02\n",
      " -5.09635508e-02 -3.24622616e-02  1.03102960e-02 -9.69109405e-03\n",
      " -4.72976454e-02 -3.12997885e-02 -3.12178098e-02  2.13835001e-01\n",
      " -6.39602616e-02 -3.61465588e-02 -4.81336564e-02 -4.66458499e-02\n",
      "  9.51355770e-02  7.54032806e-02  3.28408964e-02  7.57354423e-02\n",
      " -6.91809729e-02 -3.29126455e-02  9.32850912e-02  6.06800616e-02\n",
      " -4.02508443e-03  8.57740790e-02  8.40780139e-03  5.42509109e-02\n",
      " -4.51251902e-02 -6.67850599e-02  2.64503770e-02  2.32692733e-02\n",
      " -6.33112490e-02  6.51253387e-02 -6.17974065e-02 -5.91760613e-02\n",
      " -7.10921288e-02 -4.56610173e-02  3.72858234e-02  1.31207660e-01\n",
      "  3.46037634e-02 -3.52929346e-03 -6.48432225e-02  4.39900532e-02\n",
      " -7.93263838e-02  5.42976595e-02 -3.16974260e-02 -3.96069065e-02\n",
      " -5.15494719e-02 -5.20379581e-02 -4.53764535e-02  5.45637496e-02\n",
      "  2.39693243e-02 -2.82480642e-02  2.95167901e-02  4.15435843e-02\n",
      "  1.40691828e-02 -1.02630537e-03  1.25727087e-01 -5.25472127e-02\n",
      " -3.49038020e-02  3.67301181e-02  8.40517282e-02 -4.08195294e-02\n",
      " -3.75558026e-02  1.06689110e-01  8.04249942e-02 -1.36862800e-01\n",
      "  3.11788917e-02  4.32993053e-03  5.99742159e-02 -3.88187133e-02\n",
      "  1.51428327e-01  2.54294444e-02 -5.52151613e-02 -5.21713309e-02\n",
      " -3.83152557e-03  7.66721647e-03  1.02674002e-02 -6.63268715e-02\n",
      "  4.83414568e-02  6.08291477e-02 -6.30913004e-02 -3.95380519e-02\n",
      " -6.81978613e-02 -4.63275574e-02  9.54304338e-02  2.13326551e-02\n",
      "  7.63733089e-02 -6.45956397e-02 -4.81189676e-02 -4.30544801e-02\n",
      " -2.75521949e-02 -5.16302735e-02 -5.43423444e-02  3.43458131e-02\n",
      "  3.35725658e-02  1.69564873e-01  4.54388298e-02 -7.85622522e-02\n",
      "  5.95543534e-02 -7.82735050e-02  2.19172984e-02 -4.27247845e-02\n",
      " -3.57083380e-02 -5.87499216e-02 -1.43426163e-02 -2.42912956e-02\n",
      "  3.37268524e-02  1.04053961e-02 -5.43220900e-02 -5.31469397e-02\n",
      " -6.07080236e-02  1.28585279e-01 -4.93455827e-02 -6.63878620e-02\n",
      " -6.52912259e-02  1.13958783e-01 -2.66307089e-02  7.07729545e-04\n",
      " -2.08532754e-02 -2.77666356e-02 -4.24097069e-02 -5.02055511e-02\n",
      " -2.70337258e-02  3.32300961e-02  9.94847715e-02 -3.81047279e-02\n",
      " -7.17877522e-02 -6.39541000e-02 -4.00905423e-02  2.91260798e-02\n",
      "  6.31989539e-02 -5.49612157e-02 -6.98504820e-02 -5.58537170e-02\n",
      "  4.17412110e-02  2.13955734e-02  3.06305364e-02  1.04750089e-01\n",
      " -5.90374656e-02  9.48011801e-02  2.07461300e-03 -5.81410751e-02\n",
      " -4.55718488e-02 -2.57890746e-02 -2.81419251e-02  9.23638493e-02\n",
      " -6.25582412e-02  7.52351154e-03  1.19055256e-01 -4.37728912e-02\n",
      "  1.86216515e-02  5.67330085e-02 -1.11814989e-02 -6.78268895e-02\n",
      " -3.72987270e-04 -5.41650765e-02  1.74068660e-01 -3.95184271e-02\n",
      " -1.22201361e-01 -5.14625981e-02  7.05954880e-02 -1.03378086e-03\n",
      "  1.16505034e-01  3.00911404e-02 -6.68768585e-02 -6.56607300e-02\n",
      " -3.74066159e-02 -3.76175866e-02 -5.14175296e-02  1.45297021e-01\n",
      " -5.41283302e-02 -4.93831970e-02  6.59883171e-02 -3.55693661e-02\n",
      " -6.28777146e-02  1.31278381e-01 -4.54881266e-02 -6.37119710e-02\n",
      "  2.52564903e-02 -5.37328050e-02  8.87199491e-02 -3.49804014e-02\n",
      " -2.08283812e-02 -4.88948002e-02 -5.69767803e-02 -4.81234379e-02\n",
      "  2.76422892e-02 -4.09149863e-02  1.11335441e-02 -3.95423882e-02\n",
      "  1.60669550e-01 -4.17954735e-02  3.35571282e-02 -5.30641750e-02\n",
      " -4.17487323e-02  5.99977858e-02 -9.61758103e-03 -7.81975016e-02\n",
      " -4.04559672e-02 -4.27526012e-02 -3.07520274e-02 -3.24353352e-02\n",
      " -4.74530598e-03  1.75407454e-01  2.74002925e-02 -1.30237620e-02\n",
      " -6.91711605e-02 -2.97524072e-02 -8.74765497e-03 -2.91923210e-02\n",
      " -4.17816527e-02 -7.23442808e-02 -6.09780326e-02 -6.05338924e-02\n",
      "  6.49031997e-02  1.95154008e-02 -3.88760492e-02  5.51725626e-02\n",
      "  7.91165605e-02 -4.29694876e-02 -6.38566241e-02  5.46594597e-02\n",
      " -6.39399365e-02 -2.40685605e-02 -7.01367855e-02 -4.13773172e-02\n",
      " -6.30616620e-02 -6.48955256e-02 -1.34103939e-01  8.71945024e-02\n",
      " -1.06387384e-01 -2.46564709e-02  2.91461535e-02 -3.86474878e-02\n",
      " -4.61917259e-02 -6.78837448e-02 -5.77911586e-02 -3.21202464e-02\n",
      " -2.12506633e-02  8.22067484e-02  7.71032423e-02  5.09244092e-02\n",
      " -7.69699439e-02  7.57037178e-02  3.86015959e-02  8.52186233e-02\n",
      " -3.29900235e-02 -4.93557341e-02 -5.85895367e-02  1.53038492e-02\n",
      " -3.08165997e-02 -3.05506457e-02 -3.04898173e-02 -4.14462462e-02\n",
      " -1.31229619e-02 -1.48866291e-03 -4.77623306e-02 -6.95205405e-02\n",
      " -5.06601222e-02  7.13327602e-02 -5.55119030e-02 -7.05411956e-02\n",
      "  6.09894767e-02 -4.49795388e-02 -5.96841089e-02 -8.02420527e-02\n",
      "  1.46221399e-01 -3.91460620e-02 -5.15236892e-02 -4.34822723e-05\n",
      " -6.55449480e-02 -2.07986180e-02 -5.01917750e-02 -6.27790615e-02\n",
      " -7.80695006e-02  7.60875046e-02  1.14003785e-01 -7.93524310e-02\n",
      " -7.48876631e-02  7.51763433e-02  5.17042987e-02 -2.82351878e-02\n",
      " -4.65469770e-02 -4.70600091e-02  7.44166672e-02 -1.74258538e-02\n",
      " -4.70131487e-02  2.74593476e-02 -3.66277695e-02  1.08830839e-01\n",
      "  5.18450625e-02  5.91826886e-02 -6.52188286e-02 -4.57750447e-02\n",
      " -1.85383651e-02  7.19215646e-02  4.45907265e-02 -4.31728028e-02\n",
      " -2.20329151e-03 -3.44750620e-02  4.57471386e-02 -2.97133271e-02\n",
      " -5.05422503e-02 -2.22376473e-02 -3.19733135e-02 -4.18343246e-02\n",
      "  5.22153415e-02 -5.19768223e-02 -6.32381067e-02 -6.40806779e-02\n",
      " -4.28543910e-02  8.52631480e-02 -2.12388225e-02  7.44275237e-03\n",
      "  2.85999328e-02  1.13167472e-01  3.72961611e-02 -5.62031791e-02\n",
      " -8.13593157e-03 -6.23529516e-02 -3.37968655e-02  1.33036096e-02\n",
      " -4.33996916e-02  1.17469095e-02 -5.35602160e-02  5.93929691e-03\n",
      " -3.72334272e-02 -5.46454377e-02  5.76189794e-02 -4.15686006e-03\n",
      " -7.13002309e-02 -1.19972909e-02  4.91905287e-02 -4.82371449e-02\n",
      "  5.33495331e-03  2.30997410e-02 -3.18856016e-02 -4.53818105e-02\n",
      " -3.37173268e-02]\n",
      "Layer 26: re_lu_6 (No weights)\n",
      "Layer 27: dropout_3 (No weights)\n",
      "Layer 28: dense_1\n",
      "  Param 0 wieight: [[ 0.03779409  0.00560845 -0.06750192 ...  0.03519055 -0.09819447\n",
      "  -0.08632703]\n",
      " [ 0.00568344 -0.07010597  0.08021854 ... -0.02868285  0.02910956\n",
      "   0.0010543 ]\n",
      " [ 0.10440309 -0.13158646 -0.03333725 ... -0.06199227 -0.09108911\n",
      "  -0.12143288]\n",
      " ...\n",
      " [-0.01563178 -0.04376066 -0.05364298 ... -0.0289584  -0.06380661\n",
      "   0.03312911]\n",
      " [-0.0509207   0.02281792 -0.06939451 ... -0.03130499  0.09829951\n",
      "  -0.00223507]\n",
      " [-0.072124    0.01323608 -0.06067261 ... -0.0653367   0.06989749\n",
      "   0.03035999]]\n",
      "  Param 1 wieight: [ 0.00776812 -0.21438555  0.03775551  0.3518129  -0.06119879 -0.02881072\n",
      "  0.05851795  0.07724889 -0.31524554 -0.01420787]\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(keras_cnn_model.layers):\n",
    "    if layer.get_weights():\n",
    "        weights = layer.get_weights()\n",
    "        print(f\"Layer {i}: {layer.name}\")\n",
    "        for j, w in enumerate(weights):\n",
    "            print(f\"  Param {j} wieight: {w}\")\n",
    "    else:\n",
    "        print(f\"Layer {i}: {layer.name} (No weights)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7bae339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load weights from Keras model...\n",
      "Warning: 12 weight-bearing scratch layers were not assigned weights from the Keras model. This might be due to architecture mismatch or Keras having more layers (e.g. Dropout, InputLayer) that were skipped without a corresponding advancement in scratch layers.\n",
      "Weight loading attempt finished.\n"
     ]
    }
   ],
   "source": [
    "manual_cnn_model = CNN()\n",
    "\n",
    "for params in base_conv_params:\n",
    "    manual_cnn_model.add_layer(Conv2DLayer(num_filters=params['filters'], filter_size=params['kernel_size'], padding='same'))\n",
    "    if params.get('batch_norm'):\n",
    "        manual_cnn_model.add_layer(BatchNormalizationLayer()) # Add scratch BN\n",
    "    manual_cnn_model.add_layer(ReLULayer())\n",
    "    \n",
    "    pool_type = params.get('pool_type')\n",
    "    if pool_type == 'max':\n",
    "        manual_cnn_model.add_layer(PoolingLayer(pool_size=(2,2), stride=2, mode='max'))\n",
    "    elif pool_type == 'average':\n",
    "        manual_cnn_model.add_layer(PoolingLayer(pool_size=(2,2), stride=2, mode='average'))\n",
    "        \n",
    "    if params.get('dropout') and params['dropout'] > 0:\n",
    "        manual_cnn_model.add_layer(DropoutLayer(rate=params['dropout']))\n",
    "\n",
    "manual_cnn_model.add_layer(FlattenLayer())\n",
    "\n",
    "dense_dropout_rate_keras = 0.5\n",
    "for units in base_dense_units:\n",
    "    manual_cnn_model.add_layer(DenseLayer(output_dim=units))\n",
    "    manual_cnn_model.add_layer(ReLULayer())\n",
    "    if dense_dropout_rate_keras > 0:\n",
    "        manual_cnn_model.add_layer(DropoutLayer(rate=dense_dropout_rate_keras))\n",
    "\n",
    "manual_cnn_model.add_layer(DenseLayer(output_dim=num_classes))\n",
    "\n",
    "manual_cnn_model.load_weights_from_keras(keras_cnn_model)\n",
    "\n",
    "manual_cnn_model.loss_function = ScratchSCCE(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8fca22bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "Keras (on subset 100) - Accuracy: 0.8600, Macro F1: 0.8469\n",
      "Manual (on subset 100, loaded weights) - Accuracy: 0.0900, Macro F1: 0.0268\n",
      "\n",
      "Raw probability Comparison\n",
      "Sample 0:\n",
      "  Keras Probs (first 5):   [1.6903014e-04 1.0883027e-04 3.2663517e-04 7.9014665e-01 6.2829065e-05]\n",
      "  Manual Probs (first 5): [0.18967547 0.00952727 0.38619001 0.05030903 0.10521434]\n",
      "  Sum of Absolute Differences in Probs: 1.785557e+00\n",
      "  INFO: Probabilities differ for sample 0, potentially due to BN/Dropout behavior in Keras inference vs scratch.\n",
      "Sample 1:\n",
      "  Keras Probs (first 5):   [1.80132938e-05 2.18749736e-02 1.08058014e-10 1.47521628e-09\n",
      " 7.96869352e-13]\n",
      "  Manual Probs (first 5): [0.16882727 0.01477062 0.15245181 0.08622431 0.02858337]\n",
      "  Sum of Absolute Differences in Probs: 1.580582e+00\n",
      "  INFO: Probabilities differ for sample 1, potentially due to BN/Dropout behavior in Keras inference vs scratch.\n",
      "Sample 2:\n",
      "  Keras Probs (first 5):   [9.9479244e-04 1.2220005e-01 3.0420867e-07 1.9211768e-06 1.0228068e-08]\n",
      "  Manual Probs (first 5): [0.23153728 0.01573846 0.18788638 0.08893572 0.05511298]\n",
      "  Sum of Absolute Differences in Probs: 1.699769e+00\n",
      "  INFO: Probabilities differ for sample 2, potentially due to BN/Dropout behavior in Keras inference vs scratch.\n",
      "Sample 3:\n",
      "  Keras Probs (first 5):   [2.7392557e-01 1.7584123e-02 5.5743643e-04 4.6050432e-04 3.7085389e-05]\n",
      "  Manual Probs (first 5): [0.11137659 0.00853468 0.27289951 0.12776304 0.04422329]\n",
      "  Sum of Absolute Differences in Probs: 1.372072e+00\n",
      "  INFO: Probabilities differ for sample 3, potentially due to BN/Dropout behavior in Keras inference vs scratch.\n",
      "Sample 4:\n",
      "  Keras Probs (first 5):   [5.6647628e-11 1.8579251e-10 3.7412092e-04 9.1461461e-06 3.7626756e-05]\n",
      "  Manual Probs (first 5): [0.0640286  0.01746454 0.29628726 0.09937786 0.04010371]\n",
      "  Sum of Absolute Differences in Probs: 1.887483e+00\n",
      "  INFO: Probabilities differ for sample 4, potentially due to BN/Dropout behavior in Keras inference vs scratch.\n"
     ]
    }
   ],
   "source": [
    "x_test_subset_verify = x_test[:100]\n",
    "y_test_subset_verify_sparse = y_test_sparse[:100]\n",
    "\n",
    "keras_subset_logits_verify = keras_cnn_model.predict(x_test_subset_verify)\n",
    "keras_subset_proba_verify = tf.nn.softmax(keras_subset_logits_verify).numpy()\n",
    "keras_subset_preds_verify = np.argmax(keras_subset_proba_verify, axis=1)\n",
    "f1_keras_verify = f1_score(y_test_subset_verify_sparse, keras_subset_preds_verify, average='macro')\n",
    "acc_keras_verify = accuracy_score(y_test_subset_verify_sparse, keras_subset_preds_verify)\n",
    "print(f\"Keras (on subset {len(x_test_subset_verify)}) - Accuracy: {acc_keras_verify:.4f}, Macro F1: {f1_keras_verify:.4f}\")\n",
    "\n",
    "manual_cnn_model.loss_function = ScratchSCCE(from_logits=True)\n",
    "\n",
    "manual_subset_proba_verify = manual_cnn_model.predict_proba(x_test_subset_verify)\n",
    "manual_subset_preds_verify = np.argmax(manual_subset_proba_verify, axis=1)\n",
    "\n",
    "f1_manual_verify = f1_score(y_test_subset_verify_sparse, manual_subset_preds_verify, average='macro')\n",
    "acc_manual_verify = accuracy_score(y_test_subset_verify_sparse, manual_subset_preds_verify)\n",
    "print(f\"Manual (on subset {len(x_test_subset_verify)}, loaded weights) - Accuracy: {acc_manual_verify:.4f}, Macro F1: {f1_manual_verify:.4f}\")\n",
    "\n",
    "print(\"\\nRaw probability Comparison\")\n",
    "for i in range(5):\n",
    "    print(f\"Sample {i}:\")\n",
    "    print(f\"  Keras Probs (first 5):   {keras_subset_proba_verify[i, :5]}\")\n",
    "    print(f\"  Manual Probs (first 5): {manual_subset_proba_verify[i, :5]}\")\n",
    "    diff = np.sum(np.abs(keras_subset_proba_verify[i] - manual_subset_proba_verify[i]))\n",
    "    print(f\"  Sum of Absolute Differences in Probs: {diff:.6e}\")\n",
    "    if diff > 1e-2:\n",
    "            print(f\"  INFO: Probabilities differ for sample {i}, potentially due to BN/Dropout behavior in Keras inference vs scratch.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
